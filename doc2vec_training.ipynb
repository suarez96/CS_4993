{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\augus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scripts.TextPreprocessor import TextPreprocessor\n",
    "from scripts.OccupationPreprocessor import OccupationPreprocessor\n",
    "from scripts.TrainEngine import TrainEngine\n",
    "from scripts.Embedder import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if NOT working in colab\n",
    "data_dir = './data'\n",
    "\n",
    "# if working in colab\n",
    "# data_dir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all NOC webpage data into separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skill_type = pd.read_csv(os.path.join(data_dir, 'NOC_skilltype.csv'))\n",
    "df_major_group = pd.read_csv(os.path.join(data_dir, './NOC_majorgroup.csv'))\n",
    "df_minor_group = pd.read_csv(os.path.join(data_dir, './NOC_minorgroup.csv'))\n",
    "df = pd.read_csv(os.path.join(data_dir, './noc_data_get_byws_dealing_slash.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad missing digits from noc codes\n",
    "df['Noc_code'] = df['Noc_code'].apply(lambda x: '{0:0>4}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack all sample job titles in original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do once, if 'noc_code' column already dropped, except to skip action\n",
    "try:\n",
    "    df = df.apply(OccupationPreprocessor.extract_job_samples, axis = 1)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do same with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(OccupationPreprocessor.unpack_descriptions, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dict(OccupationPreprocessor.all_job_samples).items(), columns=['input', 'code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czAUrH4jBD0p"
   },
   "source": [
    "# Load ATP data for some train noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ATP data\n",
    "ATP_data = pd.DataFrame(pd.read_excel('./Data/V5_Run Input(1).xlsx'))\n",
    "\n",
    "# Clean codes: many show up as ''0011 or '0011\n",
    "ATP_data['code'] = ATP_data['NOC code '].apply(\n",
    "    lambda x: int(x.strip('\\''))\n",
    ").apply(OccupationPreprocessor.first_n_digits, args=(4,))\n",
    "\n",
    "ATP_data.drop(columns = ['NOC code '], inplace = True)\n",
    "\n",
    "ATP_data['input'] = ATP_data['Current Job Title']\n",
    "ATP_data.drop(columns = ['Current Job Title'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle ATP and split into train-val sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_ATP_df = ATP_data.sample(frac=1, random_state=42)\n",
    "\n",
    "# Sample size of ATP used for training \n",
    "ATP_train_size = 8000\n",
    "\n",
    "# Split  dataset \n",
    "ATP_data_train_set = shuffled_ATP_df[:ATP_train_size]\n",
    "ATP_data_test_set = shuffled_ATP_df[ATP_train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['input', 'code']]\n",
    "ATP_data_train_set = ATP_data_train_set[['input', 'code']]\n",
    "ATP_data_test_set = ATP_data_test_set[['input', 'code']]\n",
    "\n",
    "train_df = train_df.append(ATP_data_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the entire train and test input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor(strip_abbrev=True)\n",
    "train_df['input'] = train_df['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples before dropping duplicates 37745\n",
      "Train samples after dropping duplicates 33432\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples before dropping duplicates\", len(train_df))\n",
    "train_df = train_df.drop_duplicates()\n",
    "print(\"Train samples after dropping duplicates\", len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATP_data_test_set['input'] = ATP_data_test_set['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples before dropping duplicates 32024\n",
      "Test samples after dropping duplicates 14327\n"
     ]
    }
   ],
   "source": [
    "print(\"Test samples before dropping duplicates\", len(ATP_data_test_set))\n",
    "ATP_data_test_set = ATP_data_test_set.drop_duplicates()\n",
    "print(\"Test samples after dropping duplicates\", len(ATP_data_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab sample to see if preprocessing worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(string):\n",
    "    try:\n",
    "        assert '.' not in string \\\n",
    "            and ',' not in string \\\n",
    "                and ')' not in string \\\n",
    "                    and '(' not in string \\\n",
    "                        and '-' not in string \\\n",
    "                            and ';' not in string \\\n",
    "                                and '/' not in string \\\n",
    "                                    and '\\'' not in string\n",
    "    except AssertionError:\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4666</th>\n",
       "      <td>animal nutritionist</td>\n",
       "      <td>2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>industrial electrician apprentice</td>\n",
       "      <td>7242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24418</th>\n",
       "      <td>trimming machine operator woodworking</td>\n",
       "      <td>9437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10189</th>\n",
       "      <td>aviation and space museum curator</td>\n",
       "      <td>5112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15130</th>\n",
       "      <td>cable installer telecommunications</td>\n",
       "      <td>7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>coronary unit nurse</td>\n",
       "      <td>3012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>marine operations manager</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12594</th>\n",
       "      <td>freight services sales representative</td>\n",
       "      <td>6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34416</th>\n",
       "      <td>instructor 1</td>\n",
       "      <td>4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>physiological chemist</td>\n",
       "      <td>2112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38945</th>\n",
       "      <td>administrative assistant</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>accounting director</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13843</th>\n",
       "      <td>airport janitor</td>\n",
       "      <td>6733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>manager financial services</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>float clerk</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33957</th>\n",
       "      <td>tenant coordinator</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15876</th>\n",
       "      <td>railway car maintenance supervisor</td>\n",
       "      <td>7301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36809</th>\n",
       "      <td>engineering technologist and pressure equipmen...</td>\n",
       "      <td>2212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25180</th>\n",
       "      <td>hand cutter fabric fur and leather products ma...</td>\n",
       "      <td>9445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25619</th>\n",
       "      <td>yeast cutter</td>\n",
       "      <td>9461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  code\n",
       "4666                                 animal nutritionist  2121\n",
       "14970                  industrial electrician apprentice  7242\n",
       "24418              trimming machine operator woodworking  9437\n",
       "10189                  aviation and space museum curator  5112\n",
       "15130                 cable installer telecommunications  7245\n",
       "7004                                 coronary unit nurse  3012\n",
       "2095                           marine operations manager   731\n",
       "12594              freight services sales representative  6411\n",
       "34416                                       instructor 1  4021\n",
       "4541                               physiological chemist  2112\n",
       "38945                           administrative assistant  1243\n",
       "341                                  accounting director   111\n",
       "13843                                    airport janitor  6733\n",
       "441                           manager financial services   122\n",
       "3611                                         float clerk  1411\n",
       "33957                                 tenant coordinator   423\n",
       "15876                 railway car maintenance supervisor  7301\n",
       "36809  engineering technologist and pressure equipmen...  2212\n",
       "25180  hand cutter fabric fur and leather products ma...  9445\n",
       "25619                                       yeast cutter  9461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['input'].apply(check)\n",
    "display(train_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Doc2vec code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulted doc2vec param: dm=1\n"
     ]
    }
   ],
   "source": [
    "TRIAL_NAME = 'trial_11'\n",
    "\n",
    "doc2vec_params = dict(\n",
    "epochs = 6144, # training cycles\n",
    "vec_size = 64, # specific to doc2vec, size of the output vector\n",
    "alpha = 0.001, # learning rate\n",
    "window = 3,\n",
    "min_count = 2,\n",
    "min_alpha = 0.00025\n",
    ")\n",
    "\n",
    "embedder = Embedder(train_data = train_df,\n",
    "                    corpus_column = 'input',\n",
    "                    d2v_trial_name=TRIAL_NAME, \n",
    "                    d2v_params=doc2vec_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tagged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-12731fefc27a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membedder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_doc2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dropbox\\Univ\\UNB\\9th Sem\\CS 4993\\scripts\\Embedder.py\u001b[0m in \u001b[0;36mtrain_doc2vec\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m                             dm=self.doc2vec_params['dm'])\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2vec_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2vec_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tagged_data' is not defined"
     ]
    }
   ],
   "source": [
    "embedder.train_doc2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.load_doc2vec_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedder.train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_occupations = ['doctor', 'athlete', 'member of parliament',\n",
    "                    'teacher', 'researcher', 'registered nurse', \n",
    "                    'CUSTOMER SERVICE', 'MANAGER OF CLEANING BUSINESS',\n",
    "                   'CAREGIVER', 'Farm Boss']\n",
    "\n",
    "for occ in test_occupations: \n",
    "    occ = TextPreprocessor.preprocess_text(occ)\n",
    "    print(Embedder.infer_and_vote(occ, embedder, verbose=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 131364,
     "status": "ok",
     "timestamp": 1602282557549,
     "user": {
      "displayName": "Augusto Suarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-L8Zz0VgrA4IkXJW-J6TWQaOde13RXj7wSR0P=s64",
      "userId": "05858047290514616239"
     },
     "user_tz": 180
    },
    "id": "K-aKuFF9BD0q",
    "outputId": "bb6f7b18-78e8-4be0-a74c-cfdc64c6e227"
   },
   "outputs": [],
   "source": [
    "embedder.train_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply embeddings to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'input' in embedder.train_df.columns and 'code' in embedder.train_df.columns, \"Make sure train dataframe has 'input' column and 'code' column\"\n",
    "train_d2v_embeddings = train_df['input'].apply(\n",
    "    Embedder.get_doc2vec_embeddings, args=(embedder,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 0, \"Check trial 11 results before doing anything!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CODE_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_train_vectors = Embedder.vectorize_embeddings(train_d2v_embeddings)\n",
    "tfidf_train_vectors = Embedder.get_tfidf_embeddings(embedder, train_df['input'])\n",
    "\n",
    "assert d2v_train_vectors.shape[0] == tfidf_train_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_train_vectors # d2v_train_vectors\n",
    "y_train = np.array(train_df['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d2v_embeddings = ATP_data_test_set['input'].apply(\n",
    "    Embedder.get_doc2vec_embeddings, args=(embedder,)\n",
    ")\n",
    "d2v_test_vectors = Embedder.vectorize_embeddings(test_d2v_embeddings)\n",
    "tfidf_test_vectors = Embedder.get_tfidf_embeddings(embedder, ATP_data_test_set['input'])\n",
    "\n",
    "assert d2v_test_vectors.shape[0] == tfidf_test_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf_test_vectors # d2v_test_vectors\n",
    "y_test = np.array(ATP_data_test_set['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build preliminary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM = SVC(class_weight='balanced', kernel='linear')\n",
    "\n",
    "start = time.time()\n",
    "SVM.fit(X_train, y_train)\n",
    "print('SVM training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=256, max_depth=128, n_jobs=-1, warm_start=True)\n",
    "\n",
    "start = time.time()\n",
    "RF.fit(X_train, y_train)\n",
    "print('RF training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 1, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "KNN.fit(X_train, y_train)\n",
    "print('KNN training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_cw66gEMiQU"
   },
   "source": [
    "# Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWmPefoPEO_c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svm_pred = SVM.predict(X_test)\n",
    "print('SVM prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggSfm8uHERlp"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf_pred = RF.predict(X_test)\n",
    "print('RF prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLvftUL7BD1c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "knn_pred = KNN.predict(X_test)\n",
    "print('KNN prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKhah7vkBD1h"
   },
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvm3AYkfBD1i",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "tfidf_test_df = pd.DataFrame({\n",
    "    'svm_pred':svm_pred,\n",
    "    'rf_pred':rf_pred,\n",
    "    'knn_pred':knn_pred,\n",
    "    'code':y_test\n",
    "})\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)], \n",
    "                                        y_test\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)],\n",
    "                                        y_test, average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get this inside the embedder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cWEUSmGBD1m"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def ensemble_predict(row):\n",
    "\n",
    "    # find majority vote for all methods, :-1 drops ground truth column\n",
    "    votes = Counter(row[['rf_pred','svm_pred','knn_pred']]).most_common(1)\n",
    "    \n",
    "    # take svm as tie-breaker because CURRENTLY most accurate\n",
    "    winning_class, highest_num_votes = votes[0]\n",
    "    return winning_class\n",
    "    return row['svm_pred'] if highest_num_votes < 2 else winning_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvvRbrgABD1q"
   },
   "outputs": [],
   "source": [
    "tfidf_test_df['p_all'] = tfidf_test_df.drop(columns=['code']).apply(ensemble_predict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ensemble acc:{}, f1:{}'.format(accuracy_score(tfidf_test_df['p_all'], y_test), \n",
    "                                      f1_score(tfidf_test_df['p_all'], y_test, average = 'macro')))\n",
    "display(tfidf_test_df.iloc[:20][['p_all','code']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Adjust doc2vec testing to work with new code. Also get ensemble vote working for tfidf predictor\n",
    "# Is preprocessing hurting the TFIDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df = ATP_data_test_set.sample(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df['vote1'], doc2vec_test_df['vote2'], doc2vec_test_df['vote3'] = None, None, None\n",
    "doc2vec_test_df[['vote1', 'vote2' ,'vote3']] = doc2vec_test_df['input'].apply(Embedder.infer_and_vote, args = (embedder, False,))\n",
    "TPs = doc2vec_test_df.apply(lambda row: int(row['code']) in [row['vote1'], row['vote2'], row['vote3']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedder.infer_doc2vec('instructor')\n",
    "Embedder.get_tfidf_embeddings(embedder, 'instructor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['group_title'].str.contains('instructor')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATP_data_test_set.loc[ATP_data_test_set['input'] == str('instructor teacher')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TPs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d2v_embeddings = doc2vec_test_df['input'].apply(get_doc2vec_embeddings, args=(embedder,))\n",
    "doc2vec_test_df['doc2vec_embeddings'] = test_d2v_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized_embeddings = vectorize_embeddings(test_d2v_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['rf_pred'] = RF.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['knn_pred'] = KNN.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['svm_pred'] = SVM.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df[['knn_pred', 'svm_pred', 'rf_pred', 'code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        doc2vec_test_df['{}_pred'.format(classifier)], \n",
    "                                        doc2vec_test_df['code']\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        doc2vec_test_df['{}_pred'.format(classifier)],\n",
    "                                        doc2vec_test_df['code'], average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm accuracy still tanks, potentially overfitting. the problem is too many output classes. \n",
    "# to mitigate, build hierarchical model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
