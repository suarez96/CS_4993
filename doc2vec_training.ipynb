{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if NOT working in colab\n",
    "data_dir = './data'\n",
    "\n",
    "# if working in colab\n",
    "# data_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skill_type = pd.read_csv(os.path.join(data_dir, 'NOC_skilltype.csv'))\n",
    "df_major_group = pd.read_csv(os.path.join(data_dir, './NOC_majorgroup.csv'))\n",
    "df_minor_group = pd.read_csv(os.path.join(data_dir, './NOC_minorgroup.csv'))\n",
    "df = pd.read_csv(os.path.join(data_dir, './noc_data_get_byws_dealing_slash.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad missing digits from noc codes\n",
    "df['Noc_code'] = df['Noc_code'].apply(lambda x: '{0:0>4}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for different non-alphanumeric characters, EDA for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "ocurrences = 0\n",
    "\n",
    "def find_character(string, char):\n",
    "    global ocurrences\n",
    "    for occ in string.split(';'):\n",
    "        if char in occ:\n",
    "            ocurrences += 1\n",
    "        \n",
    "df['job_title'].apply(find_character, args=('.'))\n",
    "\n",
    "print(ocurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key is abbreviation, value is expanded occupation\n",
    "abbreviations_map = {}\n",
    "\n",
    "def handle_single_quotes(text):\n",
    "    \"\"\"\n",
    "    handle plurals, which are the main use of the single quote. Afterwards, drop all other single quotes\n",
    "    \"\"\"\n",
    "    text = text.replace(\"s'\", '').replace(\"'s\", '')\n",
    "    return text.replace(\"'\", '')\n",
    "\n",
    "def handle_parentheses(text, strip_abbrev):\n",
    "    \"\"\"\n",
    "    Parentheses seem to fall into two general cases in the VAST majority of instances:\n",
    "    1. Indicates an abbreviation\n",
    "    2. Indicates an exception, by using keywords such as \"except\" or \"non\"\n",
    "    \"\"\"\n",
    "    parentheses_idx = 0\n",
    "    split = text.split(\"(\")\n",
    "    for i, substr in enumerate(split):\n",
    "        if ')' in substr:\n",
    "            parentheses_idx = i\n",
    "            break\n",
    "    \n",
    "    # fragment before the fragment with the paren.\n",
    "    str1 = split[parentheses_idx-1].strip()\n",
    "    assert not ')' in str1\n",
    "    \n",
    "    # fragment w parenthesis\n",
    "    str2 = split[parentheses_idx].split(\")\")[0].strip()\n",
    "    \n",
    "    if 'except' in str2 or 'non' in str2:\n",
    "        text = text.replace(str2, '')\n",
    "        # TODO, do something with exceptions\n",
    "        \n",
    "    else:\n",
    "        # take the shorter string as the abbreviation\n",
    "        ab, ex = (str1, str2) if len(str1) < len(str2) else (str2, str1)\n",
    "    \n",
    "        # save abbreviation\n",
    "        abbreviations_map[ab] = ex\n",
    "        \n",
    "        # remove the found abbreviation from job title\n",
    "        if strip_abbrev:\n",
    "            text = text.replace(ab, '')\n",
    "\n",
    "    # remove parentheses, leading and trailing whitespace \n",
    "    text = text.replace('(','').replace(')','').strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_text(text, strip_abbrev=False):\n",
    "    \n",
    "    # handle slashes\n",
    "    text = text.replace(\"/\", ' ')\n",
    "    \n",
    "    # remove redundant semi-colons\n",
    "    text = text.strip(';')\n",
    "    \n",
    "    # hyphens are semantic noise, remove\n",
    "    text = text.replace('-', ' ')\n",
    "    \n",
    "    # handle '\n",
    "    if \"'\" in text:\n",
    "        text = handle_single_quotes(text)\n",
    "    \n",
    "    # handle ,\n",
    "    text = text.replace(\",\", '')\n",
    "    \n",
    "    # handle .\n",
    "    text = text.replace(\".\", '')\n",
    "    \n",
    "    # handle parentheses, only one check necessary since we already verified they are all paired with corresponding ')'\n",
    "    if \"(\" in text:\n",
    "        text = handle_parentheses(text, strip_abbrev=strip_abbrev)\n",
    "    \n",
    "    # remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # normalize case\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_job_samples = {}\n",
    "\n",
    "def extract_job_samples(row):\n",
    "    NOC_code = int(row['Noc_code'])\n",
    "    \n",
    "    # split jobs contained in row by ';' and .replace('-', '; ') is for '-', .replace('-', '; ')\n",
    "    # REVISE WHETHER TO KEEP - separation. logic is that lieutenant-governor can be described as lieutenant governer, no hyphen\n",
    "    # make unique set\n",
    "    # strip extra characters \n",
    "    # and take nonempty elements\n",
    "    jobs = [\n",
    "        j for j in  row['job_title'].split(';')\n",
    "        if (j != '' and j != ' ')\n",
    "    ]\n",
    "    \n",
    "    # change gendered entries such as 'chairman/woman' into separate samples, 'chairman', 'chairwoman'\n",
    "    for idx, job in enumerate(jobs):\n",
    "        if 'man/woman' in job:\n",
    "            # change original entry to 'job(man)', then append job(woman) to end of list\n",
    "            jobs[idx] = job.replace('man/woman', 'man')\n",
    "            jobs.append(job.replace('man/woman', 'woman'))\n",
    "        if 'men/women' in job:\n",
    "            jobs[idx] = job.replace('men/women', 'men')\n",
    "            jobs.append(job.replace('men/women', 'women'))\n",
    "        if 'boy/girl' in job:\n",
    "            jobs[idx] = job.replace('boy/girl', 'boy')\n",
    "            jobs.append(job.replace('boy/girl', 'girl'))\n",
    "        if 'master/mistress' in job:\n",
    "            jobs[idx] = job.replace('master/mistress', 'master')\n",
    "            jobs.append(job.replace('master/mistress', 'mistress'))\n",
    "        if 'host/hostess' in job:\n",
    "            jobs[idx] = job.replace('host/hostess', 'host')\n",
    "            jobs.append(job.replace('host/hostess', 'hostess'))\n",
    "        if 'waiter/waitress' in job:\n",
    "            jobs[idx] = job.replace('waiter/waitress', 'waiter')\n",
    "            jobs.append(job.replace('waiter/waitress', 'waitress'))\n",
    "        \n",
    "    # clean text data\n",
    "    preprocessed_jobs = [preprocess_text(job) for job in jobs]\n",
    "            \n",
    "    # remove duplicate entries\n",
    "    preprocessed_jobs = set(preprocessed_jobs)\n",
    "    \n",
    "    # parse counts of each job\n",
    "    row['n_sample_jobs'] = len(preprocessed_jobs)\n",
    "    \n",
    "    # iterate through job and add to dictionary\n",
    "    for j in preprocessed_jobs:\n",
    "        \n",
    "        if j not in all_job_samples:\n",
    "            all_job_samples[j] = NOC_code\n",
    "\n",
    "        # safe check, if job appears more than once, clause will print the both NOC Codes\n",
    "        else:\n",
    "            if all_job_samples[j] != NOC_code:\n",
    "                print(j, 'repeated', all_job_samples[j], NOC_code)\n",
    "    \n",
    "    return row\n",
    "\n",
    "def parse_1(row):\n",
    "    # get info from first digit of 4 digit code\n",
    "    row['1_digit_target'] = int(str(row['Noc_code'])[0])\n",
    "    row['1_digit_group'] = df_skill_type[df_skill_type['skilltype_code'] == row['1_digit_target']]['skilltype_title']\n",
    "        \n",
    "    return row\n",
    "\n",
    "def parse_2(row):\n",
    "    # get info from first 2 digits of 4 digit code\n",
    "    \n",
    "    # check if NOC code is long enough for parsing\n",
    "    if len(str(row['Noc_code'])) > 1:\n",
    "        row['2_digit_target'] = int(str(row['Noc_code'])[:2])\n",
    "        row['2_digit_group'] = df_major_group[df_major_group['majorgroup_code'] == '\\'' + str(row['2_digit_target'])]['majorgroup_title']\n",
    "        \n",
    "    else:\n",
    "        row['2_digit_target'] = 'NA'\n",
    "        row['2_digit_group'] = 'NA'\n",
    "    \n",
    "    return row\n",
    "\n",
    "def parse_3(row):\n",
    "    # get info from first 3 digits of 4 digit code\n",
    "    \n",
    "    # check if NOC code is long enough for parsing\n",
    "    if len(str(row['Noc_code'])) > 2:\n",
    "        row['3_digit_target'] = int(str(row['Noc_code'])[:3])\n",
    "        row['3_digit_group'] = df_minor_group[df_minor_group['minorgroup_code'] == '\\'' + str(row['3_digit_target'])]['minorgroup_title']\n",
    "        \n",
    "    else:\n",
    "        row['3_digit_target'] = 'NA'\n",
    "        row['3_digit_group'] = 'NA'\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29518"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do once, if 'noc_code' column already dropped, except to skip action\n",
    "try:\n",
    "    df = df.apply(parse_1, axis = 1)\n",
    "    df = df.apply(parse_2, axis = 1)\n",
    "    df = df.apply(parse_3, axis = 1)\n",
    "    df = df.apply(extract_job_samples, axis = 1)\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "len(all_job_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptions = {}\n",
    "desc_counts = []\n",
    "def unpack_descriptions(row):\n",
    "    # unpack all descriptions from a row and\n",
    "    duty = row['main_duties']\n",
    "    desc_counts.append(0)\n",
    "    \n",
    "    # split duty field into separate duties and remove initial generic blurb\n",
    "    for description in duty.strip('-').split(';'):\n",
    "        if 'duties' not in description:\n",
    "            all_descriptions[description] = row['Noc_code']\n",
    "            desc_counts[-1] += 1\n",
    "            \n",
    "    return row\n",
    "\n",
    "df = df.apply(unpack_descriptions, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dictionary from selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dict(all_job_samples)\n",
    "# train_df.update(all_descriptions)\n",
    "train_df = pd.DataFrame(train_df.items(), columns = ['input', 'code'])\n",
    "train_df['input'] = train_df['input'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab sample to see if preprocessing worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(string):\n",
    "    try:\n",
    "        assert '.' not in string \\\n",
    "            and ',' not in string \\\n",
    "                and ')' not in string \\\n",
    "                    and '(' not in string \\\n",
    "                        and '-' not in string \\\n",
    "                            and ';' not in string \\\n",
    "                                and '/' not in string \\\n",
    "                                    and '\\'' not in string\n",
    "    except AssertionError:\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>investment manager financial brokerage</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22611</th>\n",
       "      <td>disc flanging operator metal fabrication</td>\n",
       "      <td>9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>financial brokerage manager</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>medical missionary</td>\n",
       "      <td>3112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>homemaker services director social services</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>laundry and dry cleaning foreman</td>\n",
       "      <td>6316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>room flipper</td>\n",
       "      <td>6721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15039</th>\n",
       "      <td>facilities wirer telecommunications</td>\n",
       "      <td>7246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11648</th>\n",
       "      <td>roller skating instructor</td>\n",
       "      <td>5254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21371</th>\n",
       "      <td>rotary furnace tender chemical processing</td>\n",
       "      <td>9232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>archaeology professor university</td>\n",
       "      <td>4011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9477</th>\n",
       "      <td>political historian</td>\n",
       "      <td>4169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>water polo coach</td>\n",
       "      <td>5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27187</th>\n",
       "      <td>barrel inspector wood products manufacturing</td>\n",
       "      <td>9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12288</th>\n",
       "      <td>diamond sawyer</td>\n",
       "      <td>6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23575</th>\n",
       "      <td>radial tire builder</td>\n",
       "      <td>9423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>health care association president</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13385</th>\n",
       "      <td>cafeteria helper</td>\n",
       "      <td>6711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>petrochemical laboratory technologist</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23850</th>\n",
       "      <td>sheet paper inspector</td>\n",
       "      <td>9433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input  code\n",
       "508          investment manager financial brokerage   121\n",
       "22611      disc flanging operator metal fabrication  9416\n",
       "522                     financial brokerage manager   121\n",
       "7173                             medical missionary  3112\n",
       "1303    homemaker services director social services   423\n",
       "12063              laundry and dry cleaning foreman  6316\n",
       "13453                                  room flipper  6721\n",
       "15039           facilities wirer telecommunications  7246\n",
       "11648                     roller skating instructor  5254\n",
       "21371     rotary furnace tender chemical processing  9232\n",
       "8185               archaeology professor university  4011\n",
       "9477                            political historian  4169\n",
       "11547                              water polo coach  5252\n",
       "27187  barrel inspector wood products manufacturing  9533\n",
       "12288                                diamond sawyer  6344\n",
       "23575                           radial tire builder  9423\n",
       "180               health care association president    14\n",
       "13385                              cafeteria helper  6711\n",
       "5459          petrochemical laboratory technologist  2211\n",
       "23850                         sheet paper inspector  9433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['input'].apply(check)\n",
    "display(train_df.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_n_digits(string, n=4):\n",
    "    \n",
    "    # if default number of digits desired, don't do anything\n",
    "    if n == 4:\n",
    "        return string\n",
    "    \n",
    "    # else pad left with zeros until 4 digits reached\n",
    "    padded_str = '{0:0>4}'.format(string)\n",
    "    return padded_str[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X = train_df['input']\n",
    "\n",
    "y1 = train_df['code'].apply(first_n_digits, args = (1,)).astype('int')\n",
    "y2 = train_df['code'].apply(first_n_digits, args = (2,)).astype('int')\n",
    "y3 = train_df['code'].apply(first_n_digits, args = (3,)).astype('int')\n",
    "y4 = train_df['code'].apply(first_n_digits, args = (4,)).astype('int')\n",
    "\n",
    "# select how many digits to train on\n",
    "y = y4\n",
    "\n",
    "X_train, y_train = X, y\n",
    "\n",
    "corpus = list(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For window size calculation, get mean length of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.511717953943346"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(x.split()) for x in X_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Doc2vec code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\augus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(item.lower()), tags=[str(i)]) for i, item in enumerate(corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Model trial_9.model Found\n"
     ]
    }
   ],
   "source": [
    "TRIAL_NAME = 'trial_9'\n",
    "curr_model_name = \"{}.model\".format(TRIAL_NAME)\n",
    "\n",
    "epochs = 4096 # training cycles\n",
    "vec_size = 32 # specific to doc2vec, size of the output vector\n",
    "alpha = 0.001 # learning rate\n",
    "window = 3\n",
    "min_count = 2\n",
    "min_alpha = 0.00025\n",
    "\n",
    "try:\n",
    "    assert not os.path.exists(curr_model_name), \"Model {} already exists! Update model output name\".format(curr_model_name)\n",
    "\n",
    "\n",
    "    model = Doc2Vec(vector_size=vec_size,\n",
    "                    alpha=alpha, \n",
    "                    window=window,\n",
    "                    min_alpha=min_alpha,\n",
    "                    min_count= min_count,\n",
    "                    dm=1)\n",
    "\n",
    "    model.build_vocab(tagged_data)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train(tagged_data,\n",
    "                    total_examples=model.corpus_count,\n",
    "                    epochs=model.epochs)\n",
    "        # LR scheduling\n",
    "        model.alpha -= 0.00002\n",
    "\n",
    "    model.save(curr_model_name)\n",
    "    print(\"Model {} Saved\".format(curr_model_name))\n",
    "\n",
    "except AssertionError:\n",
    "    print(\"Existing Model {} Found\".format(curr_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "detokenizer = TreebankWordDetokenizer()\n",
    "\n",
    "model= Doc2Vec.load(curr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_doc2vec_encoding(occ, steps=128, alpha=0.03):\n",
    "    test_data = word_tokenize(occ)\n",
    "    test_vector = model.infer_vector(test_data, steps=steps, alpha=alpha)\n",
    "    return test_vector\n",
    "\n",
    "def get_occ_and_code_from_tokens(training_doc):\n",
    "    \"\"\"\n",
    "    Return the train input in readable form as well as its corresponding NOC code\n",
    "    \"\"\"\n",
    "    tokens = tagged_data[int(training_doc[0])][0]\n",
    "    \n",
    "    detokenized_job = detokenizer.detokenize(tokens)\n",
    "        \n",
    "    try:\n",
    "        code = int(train_df[train_df['input'] == detokenized_job]['code'])\n",
    "    except TypeError:\n",
    "        try: # TEMPORARY WHILE WE FIX PARENTHESES PROBLEM\n",
    "            code = int(\n",
    "                train_df.loc[train_df['input'].str.contains(detokenized_job.split('(')[0]), 'code'].values[0]\n",
    "            )\n",
    "        except ValueError:\n",
    "            code = 0\n",
    "        except IndexError:\n",
    "            code = 0\n",
    "    \n",
    "    return detokenized_job, code\n",
    "\n",
    "def infer(str_input, verbose=False):\n",
    "    \n",
    "    preprocessed_str = preprocess_text(str_input)\n",
    "    \n",
    "    job_vector = get_doc2vec_encoding(preprocessed_str)\n",
    "    \n",
    "    # to find most similar doc using tags\n",
    "    similar_doc = model.docvecs.most_similar([job_vector])\n",
    "    \n",
    "    codes = []\n",
    "    \n",
    "    if verbose:\n",
    "        print('---------Test on {}---------'.format(preprocessed_str))\n",
    "    \n",
    "    for doc in similar_doc:\n",
    "        \n",
    "        job, code = get_occ_and_code_from_tokens(doc)\n",
    "                \n",
    "        codes.append(code)\n",
    "        \n",
    "        if verbose:\n",
    "            print('{} - {}'.format(job, code))\n",
    "    \n",
    "    return Counter(codes)\n",
    "\n",
    "def process_counter(counter):\n",
    "    \n",
    "    if len(counter) >= 3:\n",
    "        v1, v2, v3 = (int(w) for w, c in counter.most_common(3))\n",
    "        \n",
    "    elif len(counter) == 2:\n",
    "        v1, v2  = (int(w) for w, c in counter.most_common(2))\n",
    "        v3 = 0\n",
    "        \n",
    "    elif len(counter) == 1:\n",
    "        v1 = counter.most_common(1)[0][0]\n",
    "        v2, v3 = 0, 0\n",
    "            \n",
    "    return pd.Series([v1, v2, v3])\n",
    "\n",
    "def infer_and_vote(occ, verbose=False):\n",
    "    counter = infer(occ, verbose=verbose)\n",
    "    return process_counter(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Test on doctor---------\n",
      "locum doctor - 3112\n",
      "osteopathic doctor - 3125\n",
      "medical doctor - 3112\n",
      "chinese medicine doctor - 3232\n",
      "saw doctor - 7384\n",
      "naturopathic doctor - 3125\n",
      "chiropractic doctor - 3122\n",
      "missionary doctor - 3112\n",
      "doctor office receptionist - 1414\n",
      "doctor office nurse - 3012\n",
      "0    3112\n",
      "1    3125\n",
      "2    3232\n",
      "dtype: int64\n",
      "---------Test on athlete---------\n",
      "athlete - 5251\n",
      "circus artist - 5232\n",
      "author - 5121\n",
      "amateur athlete - 5251\n",
      "theatrical business agent - 1123\n",
      "flat knitter - 9442\n",
      "artistic floral designer - 5244\n",
      "humorist author - 5121\n",
      "link machine knitter - 9442\n",
      "artistic bouquet designer - 5244\n",
      "0    5251\n",
      "1    5121\n",
      "2    9442\n",
      "dtype: int64\n",
      "---------Test on member of parliament---------\n",
      "fishing vessel boun - 8261\n",
      "human resources assistant - 1415\n",
      "fishing vessel checkerman - 8441\n",
      "fishing vessel checkerwoman - 8441\n",
      "fishing vessel skiffman - 8441\n",
      "fishing vessel skiffwoman - 8441\n",
      "fishing vessel netmender - 8441\n",
      "executive housekeeper - 6312\n",
      "fishing vessel captain - 8261\n",
      "human resources clerk - 1415\n",
      "0    8441\n",
      "1    8261\n",
      "2    1415\n",
      "dtype: int64\n",
      "---------Test on teacher---------\n",
      "french as a second language teacher - 4021\n",
      "english as a second language teacher - 4021\n",
      "printmaking teacher - 5136\n",
      "embalming teacher - 4021\n",
      "teacher seminary - 4021\n",
      "finger spelling teacher - 4215\n",
      "sculpturing teacher - 5136\n",
      "elementary school substitute teacher - 4032\n",
      "teacher of persons who are blind - 4215\n",
      "teacher assistant - 4413\n",
      "0    4021\n",
      "1    5136\n",
      "2    4215\n",
      "dtype: int64\n",
      "---------Test on researcher---------\n",
      "poverty researcher - 4164\n",
      "nutrition researcher - 3132\n",
      "nursing researcher - 3012\n",
      "health services researcher - 4165\n",
      "speech language pathologist researcher - 3141\n",
      "chemistry researcher - 2112\n",
      "natural and applied sciences researcher - 4161\n",
      "social researcher - 4164\n",
      "dance therapy researcher - 3144\n",
      "health care researcher - 4165\n",
      "0    4164\n",
      "1    4165\n",
      "2    3132\n",
      "dtype: int64\n",
      "---------Test on registered nurse---------\n",
      "registered nurse - 3012\n",
      "occupational medicine nurse - 3012\n",
      "intensive care nurse - 3012\n",
      "critical care nurse - 3012\n",
      "medical intensive care nurse - 3012\n",
      "neuroscience nurse - 3012\n",
      "registered nurse telehealth - 3012\n",
      "newspaper editor - 5122\n",
      "pediatric nurse - 3012\n",
      "registered industrial nurse - 3012\n",
      "0    3012\n",
      "1    5122\n",
      "2       0\n",
      "dtype: int64\n",
      "---------Test on customer service---------\n",
      "pay and benefits supervisor - 1212\n",
      "automotive body shop supervisor - 7301\n",
      "automotive radiator installer - 7535\n",
      "consumer advisor - 4164\n",
      "customer service adviser - 6552\n",
      "call centre agent customer service - 6552\n",
      "customer accounts supervisor - 6314\n",
      "railway car stenciller - 9536\n",
      "automotive body shop forewoman - 7301\n",
      "automotive body shop foreman - 7301\n",
      "0    7301\n",
      "1    6552\n",
      "2    1212\n",
      "dtype: int64\n",
      "---------Test on manager of cleaning business---------\n",
      "ironer laundry and dry cleaning - 6741\n",
      "presser laundry and dry cleaning - 6741\n",
      "shirt presser laundry and dry cleaning - 6741\n",
      "maid cleaning services - 6731\n",
      "pleat presser laundry and dry cleaning - 6741\n",
      "housemaid cleaning services - 6731\n",
      "cleaning lady - 6731\n",
      "organization and productivity project manager - 1221\n",
      "folder laundry and dry cleaning - 6741\n",
      "tagger laundry and dry cleaning - 6741\n",
      "0    6741\n",
      "1    6731\n",
      "2    1221\n",
      "dtype: int64\n",
      "---------Test on caregiver---------\n",
      "babysitting caregiver - 4411\n",
      "kinship caregiver - 4411\n",
      "family caregiver - 4412\n",
      "live in caregiver seniors - 4412\n",
      "child care live in caregiver - 4411\n",
      "live in nanny - 4411\n",
      "live in housekeeper - 4412\n",
      "fast food preparer - 6711\n",
      "community preventive medicine physician - 3112\n",
      "nanny - 4411\n",
      "0    4411\n",
      "1    4412\n",
      "2    6711\n",
      "dtype: int64\n",
      "---------Test on farm boss---------\n",
      "farm boss - 8252\n",
      "farm machinery builder - 7316\n",
      "drill fitter boss mining - 8221\n",
      "coal hauler - 7511\n",
      "farm tractor repairer - 7312\n",
      "traffic light repairer - 7244\n",
      "farm machinery fitter - 7316\n",
      "coal loader unloader - 7452\n",
      "medical information assistant - 1222\n",
      "stable boss - 8252\n",
      "0    8252\n",
      "1    7316\n",
      "2    8221\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_occupations = ['doctor', 'athlete', 'member of parliament',\n",
    "                    'teacher', 'researcher', 'registered nurse', \n",
    "                    'CUSTOMER SERVICE', 'MANAGER OF CLEANING BUSINESS',\n",
    "                   'CAREGIVER', 'Farm Boss']\n",
    "\n",
    "for occ in test_occupations: \n",
    "    print(infer_and_vote(occ, verbose=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply embeddings to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d2v_embeddings = train_df['input'].apply(get_doc2vec_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_embeddings(data):\n",
    "    return np.array([list(x) for x in np.array(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['doc2vec_embeddings'] = train_d2v_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CODE_LENGTH = 4\n",
    "\n",
    "classifier_input = vectorize_embeddings(train_d2v_embeddings)\n",
    "classifer_output = np.array(train_df['code'].apply(first_n_digits, args = (TARGET_CODE_LENGTH,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build preliminary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.000398\n",
      "-17.926199\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZX0lEQVR4nO3de5Bc5X3m8e9vunt6LrrNIIEkRiDJCNYKDhfPsrBOKmYNBEgKOV57LZIq4yQuVWVN7W62arNQ7Ga9SW2Vs5vsel2mAlriDUk5wQ4bgmzLEWBjO4ljwlDhNoBACIyGkdAISaPLXPr22z/6nVFPd89F093TPec8n6quPuc9b5/37ZmjR++8ffocc3dERCT62prdARERWRoKfBGRmFDgi4jEhAJfRCQmFPgiIjGRbHYH5rJ27VrfvHlzs7shIrJsPPfcc8fcfV21bS0d+Js3b2ZgYKDZ3RARWTbM7CezbdOUjohITCjwRURiQoEvIhITCnwRkZhQ4IuIxIQCX0QkJhT4IiIxocAXEWkhT77yHg/84M2G7FuBLyLSQp7ef5SH/uathuxbgS8iEhMKfBGRmFDgi4jEhAJfRCQmFPgiIjGhwBcRiQkFvohIC3Fv3L4V+CIiLcUxa8yeFfgiIi3EHRqU9wp8EZFW4o5G+CIiceA41qAxvgJfRKTFaIQvIhIDOktHRCQmHH1oKyISC8UPbTWHLyISeU7j5nTqEvhm9lUzO2pmL8+y3czsy2Z2wMxeNLNr69GuiEjkLIPTMv8YuHWO7bcB28JjF/CHdWpXRCRSnBYPfHf/IXB8jio7gD/xoh8Da8xsQz3aFhGJEvflfx7+xcChkvWhUFbBzHaZ2YCZDYyMjCxJ50REWkXLj/AXoFr3q34y4e673b3f3fvXrVvX4G6JiLSWKFxLZwjYVLLeBwwvUdsiIstGcYS/vKd09gCfCWfrXA+MuvvhJWpbRGTZKM7hN0ayHjsxsz8HPgqsNbMh4L8AKQB3fwDYC9wOHADGgF+tR7siIlHj0LA5nboEvrvfOc92Bz5fj7ZERCItAnP4IiKyAI4v+zl8ERFZgCicpSMiIgugO16JiMSE7nglIhITGuGLiMREA294pcAXEWklugGKiEhsNO6btgp8EZEWojl8EZGYiMLlkUVEZAGicAMUERFZAI3wRURiQpdWEBGJieLlkTWlIyISeY28AYoCX0SkxWgOX0QkBjSHLyISE97Aq+ko8EVEWoyupSMiEgOa0hERiYmWv5aOmd1qZvvN7ICZ3VNl+2fNbMTMng+Pz9WjXRGRqGnkHa+Ste7AzBLA/cDNwBDwrJntcfdXyqp+3d3vrrU9EZEoc6dhczr1GOFfBxxw94PungEeAXbUYb8iIrHTwLyvS+BfDBwqWR8KZeX+pZm9aGaPmtmm2XZmZrvMbMDMBkZGRurQPRGRZaTF5/Crda38RNJvApvd/aeBp4CHZ9uZu+92935371+3bl0duicisnw0cg6/HoE/BJSO2PuA4dIK7v6+u0+G1f8DfLgO7YqIRE6rn6XzLLDNzLaYWTuwE9hTWsHMNpSs3gG8Wod2RUQip5HXw6/5LB13z5nZ3cA+IAF81d0Hzex3gAF33wP8GzO7A8gBx4HP1tquiEgU5QpOoq0xX5GqOfAB3H0vsLes7LdLlu8F7q1HWyIiUXZ6IktfT2dD9q1v2oqItJBT4zlWdaQasm8FvohICzk1kWVVZ10mXyoo8EVEWsRENk8mV9AIX0Qk6k5P5ABY1anAFxGJtJHTxa8r9Xa1N2T/CnwRkRZx8NgZAC69oKsh+1fgi4i0iH985yTpZBuXX7SyIftX4IuItIjnfnKCq/rW0J5sTDQr8EVEWsCpiSyDw6Nce2lPw9pQ4IuItIDHnx8mm3duvXJ9w9pQ4IuINNlYJscD33+Tq/pWc1Xf6oa1o8AXEWkid+c//9Ug754c575f2I416lKZ1OniaSIicv5OTWT5D3/xAvsG3+M3b7qc67b0NrQ9Bb6IyBJzd76/f4QvfHOQoRPj/Kdf+CC//jNbGt6uAl9EZAkUCs7zQyfZN3iEJwbf461jZ7n0gi4e2XU9/3RzY0f2UxT4IiINMpnL8+ODx3li8AhPvvIeR09PkmwzbvjABfzGz32Aj19zccPOua9GgS8iUgN3Z3Q8y6Hj47xzfGz68dqRUwwOnyKTK9DVnuCjV6zjlu3rufGKC1nd1ZiLo81HgS8iMo/JXJ53T4xz6EQx1A8dH+Od98c4dKIY7lNXuZzS05Vi20UrueuGS7l+6wV85LK1dKQSTer9OQp8EYmdfME5NZ7lxFiGE2NZTpzNcHwsw8mxDMfPFtffPzvJyJkMR09NcOTUBO7nXp9OttHX08klvV30X9rDpt4uNvV2cUl4XpFuzWhtzV6JiJTJF5yJbJ6JbJ7xqedMgfFsnrOTOU5NZDkzmeP0RI4zEzlOT2Q5HdZPT2Q5NV6sMzqerRiRl0oljJ6udnq721m3Ms1l69ayqbdzOswv6e1i3Yo0bW2NO1++UeoS+GZ2K/C/gQTwkLt/sWx7GvgT4MPA+8Cn3f3terQtIs01FcTj2TzjmdJALlSUjWfyTOTyTGTCegjtyrJ8CPfCdFkmV1hwn9oMVnakWJFOsrIjyaqOFBvXdHBFx0pWd6amHz3dqelw7+lqp6e7ne72REO//NRMNQe+mSWA+4GbgSHgWTPb4+6vlFT7deCEu19mZjuB3wM+XWvbIlJUKDiZfIHJXIFMrkAmXyAbnjO5c+XZ/LntmVA2GZanR88hlMczhRlBPTWqnhnuxX0tRmcqQWd7gs5Ugo5UGx2p4vKKdJK1K9LT5Z2pBB2h3tRrOpLnyjpSbSHYU6zsKAZ8Zyq6oV2LeozwrwMOuPtBADN7BNgBlAb+DuALYflR4CtmZu6ls2Iirc+9GKzZvE8HZjFA82RyPiNIq5bl8sXXloZzlSCerBLaM4K6rCxfqM8/JTOmg7VjKnBDsK7sSHLhyvR0MHe2J0qW20L9smAuCfJz4Z4gnWxTIDdBPQL/YuBQyfoQ8M9mq+PuOTMbBS4AjtWhfYm4qZCdzBWYzBaYzOUrlqdCcjKXnzGinczlmQyj0NKyc0GcLxkR+/RoN5PLT5eVh2s9tSfaaE+2kUoY7cnicrEsQXso60i1saojGeoV66Sn650rm3ptukrZnMvhWUEcffUI/GpHR/lwYyF1ihXNdgG7AC655JLaeiYNUSg4k7lClfnWyj//i8vnpgum5mUnc+eeJ8N0wmRJaE9kC0yWlNXKjOkwbE8mwvPMAEwljNXtqZJ6JUGcSJQEpc0M5lDv3D4TM16bLnt9quT1CldZSvUI/CFgU8l6HzA8S50hM0sCq4Hj1Xbm7ruB3QD9/f2a8lmkfME5m8lxdrL4ODOZn14+mzm3PvNDtmI4V3zINmN7MYwXI50sTg+kk22kk8U/96eeu9qT9HQVR5lTo9p0COZ0auo1ZctT64k20iX1Z4x2Q/1kmylcJfbqEfjPAtvMbAvwLrAT+OWyOnuAu4C/Bz4JfE/z99W5OxPZAqPjxdPHTk1kOTW1HE4nK55qVlwuhnieMyHIp9bHs/kFtzkVxFNzr+lUgs4wd9vTlaqYg01Pz9O2lc3jls79JmbuM9m2LE9jE4mSmgM/zMnfDeyjeFrmV9190Mx+Bxhw9z3AHwF/amYHKI7sd9ba7nIynskzPDrOkdEJRk5PcuzMJMfPZjh+NjP9xY+TYxlOjmU5OZ6d9/Sz4lkJxTMSutMJutuTbFjdQXc6SXc6yYp0orjcngxlxTMfittCWXuxTmcqoSAWiYm6nIfv7nuBvWVlv12yPAF8qh5ttZpsvsCR0QkOj05weHScd0+Oc/hkcXn45ATDo+OcHMtWvC7ZZqzpaqe3O8Warna2rO2mp6ud1V2pGecJr+o4t1w85Sy1pBdbEpHo0DdtF2Aim+f1907z+ntneOPoaQ4dH2M4hPrR05OUT06t7kyxYXUHG9d0cu2la9iwupONazpYv6qTC1eluaC7ndWdKc0pi8iSUuCXcXfeOnaWgbdP8Ozbx3lxaJQDI2emz3NuT7TR19vJxtWd/Nzl66bDvPS5u0WvoyEi8aZkAjK5An934Bj7Bo/wg9dHODw6ARSveHf1pjXc8lMX8cENq7j8opVsvqCLZEJTKiKy/MQ68I+dmeShv3mLR559h5NjWVakk/zstrV8/sa1XL+1l61rV+gDTRGJjFgG/tHTEzz4g4N87ZmfMJkrcNuV6/nENX387OVrSSebf81qEZFGiF3gf+elw/zWoy8yls2z4+qNfP7Gy/jAuhXN7paISMPFKvAf/tHbfOGbg1y9aQ1/8Kmr2KqgF5EYiUXguzu//8R+7n/6TW764EV85ZevaYnbjYmILKVYBP7DP3qb+59+kzuv28Tv7rhSZ9mISCxFPvDfPTnOF//6NW68Yh3/7eMf0lk3IhJbkR/qfunJ1yk4/O7Hr1TYi0isRTrwT01kefyFYf5Vfx99PV3N7o6ISFNFOvD3vXyETK7AJ67ta3ZXRESaLtKBv+eFYTb1dnLNpjXN7oqISNNFNvAnsnl+9Ob73P6hDboqpYgIEQ78146cJl9wrtnU0+yuiIi0hMgG/svvjgJw5cWrmtwTEZHWENnAHxweZXVniovXdDa7KyIiLSHCgX+Kn9q4SvP3IiJBZAP/rWNnuexCXRxNRGRKJAN/LJPj9ESO9as7mt0VEZGWUVPgm1mvmT1pZm+E56qnxJhZ3syeD489tbS5EO+fyQCwdkW60U2JiCwbtY7w7wG+6+7bgO+G9WrG3f3q8LijxjbnNXJmEoB1CnwRkWm1Bv4O4OGw/DDw8Rr3VxcnzhZH+L3d7U3uiYhI66g18C9y98MA4fnCWep1mNmAmf3YzOb8T8HMdoW6AyMjI4vq1JnJHAArOiJ/9WcRkQWbNxHN7ClgfZVN951HO5e4+7CZbQW+Z2Yvufub1Sq6+25gN0B/f7+fRxvTzk7mAehuV+CLiEyZNxHd/abZtpnZe2a2wd0Pm9kG4Ogs+xgOzwfN7PvANUDVwK+Hs2GE353WbQxFRKbUOqWzB7grLN8FPF5ewcx6zCwdltcCHwFeqbHdOU1N6XRphC8iMq3WwP8icLOZvQHcHNYxs34zeyjU+SAwYGYvAE8DX3T3hgb+WCZHZypBQne4EhGZVtMQ2N3fBz5WpXwA+FxY/hHwoVraOV9jmTyd7ZrOEREpFclv2k7mCnQkI/nWREQWLZKpmM0XSCnwRURmiGQq5gpOUvP3IiIzRDLw83kn2RbJtyYismiRTMVcwXWGjohImUgGfr5QIJlQ4IuIlIpk4GuELyJSKZKBn9eHtiIiFSIZ+Brhi4hUimTgF0f4kXxrIiKLFslU1AhfRKRSJAM/Xygo8EVEykQy8HN5jfBFRMpFMvAL7iRMgS8iUiqSgQ+gvBcRmSmSge+LuhOuiEi0RTLwQSN8EZFykQx8DfBFRCpFMvABDA3xRURKRTLwXZP4IiIVIhn4ABrgi4jMVFPgm9mnzGzQzApm1j9HvVvNbL+ZHTCze2ppcyE0vhcRqVTrCP9l4BPAD2erYGYJ4H7gNmA7cKeZba+x3XlpgC8iMlOylhe7+6sANvc5kNcBB9z9YKj7CLADeKWWtufuWMP2LCKybC3FHP7FwKGS9aFQVpWZ7TKzATMbGBkZWXSj8/wnJCISO/OO8M3sKWB9lU33ufvjC2ijWvLOOgZ3993AboD+/v5FjdU1wBcRqTRv4Lv7TTW2MQRsKlnvA4Zr3Oe8NL4XEZlpKaZ0ngW2mdkWM2sHdgJ7GtmgzsMXEalU62mZv2RmQ8ANwLfNbF8o32hmewHcPQfcDewDXgW+4e6DtXV7IX1rdAsiIstLrWfpPAY8VqV8GLi9ZH0vsLeWts6rX0vVkIjIMhLZb9pqgC8iMlMkA19T+CIilSIZ+KDz8EVEykUy8F2z+CIiFSIZ+KA5fBGRcpENfBERmSmSga8PbUVEKkUy8AHN6YiIlIlk4GuELyJSKZKBD7qJuYhIucgGvoiIzBTZwNf3rkREZopk4OvyyCIilSIZ+KCTdEREykUy8DW+FxGpFMnAB83hi4iUi2TgawpfRKRSJAMfdB6+iEi5SAa+Lo8sIlIpkoEPmsMXESkXycDXHL6ISKWaAt/MPmVmg2ZWMLP+Oeq9bWYvmdnzZjZQS5sL79tStCIisnwka3z9y8AngAcXUPdGdz9WY3sLogG+iEilmgLf3V+FVr1heCv2SUSkeZZqDt+BJ8zsOTPbNVdFM9tlZgNmNjAyMrK4xjTEFxGpMO8I38yeAtZX2XSfuz++wHY+4u7DZnYh8KSZvebuP6xW0d13A7sB+vv7Fx3dLflHh4hIE80b+O5+U62NuPtweD5qZo8B1wFVA78+NMQXESnX8CkdM+s2s5VTy8AtFD/sbWy7jW5ARGSZqfW0zF8ysyHgBuDbZrYvlG80s72h2kXA35rZC8A/AN9297+upd35aA5fRKRSrWfpPAY8VqV8GLg9LB8ErqqlncXQHL6IyEzR/KZtszsgItKCIhn4oKtlioiUi2Tg6562IiKVIhn4oDl8EZFykQ18ERGZKZKBrwkdEZFKkQx80BevRETKRTLw9ZmtiEilSAY+tOolm0VEmieSga/TMkVEKkUy8EVEpFIkA1/jexGRSpEMfNAXr0REykUz8DXEFxGpEM3ARxdPExEpF8nA1wBfRKRSJAMfNIcvIlIukoGv8/BFRCpFMvBB19IRESkXycDX+F5EpFJNgW9m/8PMXjOzF83sMTNbM0u9W81sv5kdMLN7amlz4X1bilZERJaPWkf4TwJXuvtPA68D95ZXMLMEcD9wG7AduNPMttfY7pw0hS8iUqmmwHf3J9w9F1Z/DPRVqXYdcMDdD7p7BngE2FFLuwuhq2WKiMxUzzn8XwO+U6X8YuBQyfpQKKvKzHaZ2YCZDYyMjCyqI7deuZ5/sn7lol4rIhJVyfkqmNlTwPoqm+5z98dDnfuAHPC1aruoUjbrpIu77wZ2A/T39y9qcuZ/ffrqxbxMRCTS5g18d79pru1mdhfwi8DHvPoJ8EPAppL1PmD4fDopIiK1q/UsnVuB/wjc4e5js1R7FthmZlvMrB3YCeyppV0RETl/tc7hfwVYCTxpZs+b2QMAZrbRzPYChA917wb2Aa8C33D3wRrbFRGR8zTvlM5c3P2yWcqHgdtL1vcCe2tpS0REahPJb9qKiEglBb6ISEwo8EVEYkKBLyISE9bK1443sxHgJ4t8+VrgWB27s9zE/f2Dfgagn0Ec3/+l7r6u2oaWDvxamNmAu/c3ux/NEvf3D/oZgH4GcX//5TSlIyISEwp8EZGYiHLg7252B5os7u8f9DMA/Qzi/v5niOwcvoiIzBTlEb6IiJRQ4IuIxETkAr8ZN0yvJzPbZGZPm9mrZjZoZv82lPea2ZNm9kZ47gnlZmZfDu/3RTO7tmRfd4X6b4T7FkyVf9jMXgqv+bKF+0HO1kazmFnCzP7RzL4V1reY2TOhf18Pl9vGzNJh/UDYvrlkH/eG8v1m9vMl5VWPk9naaAYzW2Nmj5rZa+F4uCFOx4GZ/Wb4N/Cymf25mXXE7RioO3ePzANIAG8CW4F24AVge7P7dZ7vYQNwbVheSfHm8NuB/w7cE8rvAX4vLN9O8daSBlwPPBPKe4GD4bknLPeEbf8A3BBe8x3gtlBetY0m/iz+PfBnwLfC+jeAnWH5AeA3wvK/Bh4IyzuBr4fl7eEYSANbwrGRmOs4ma2NJr3/h4HPheV2YE1cjgOKt0F9C+gs+b18Nm7HQN1/rs3uQJ0PkhuAfSXr9wL3NrtfNb6nx4Gbgf3AhlC2Adgflh8E7iypvz9svxN4sKT8wVC2AXitpHy63mxtNOl99wHfBf4F8K0QSseAZPnvmuK9Fm4Iy8lQz8p//1P1ZjtO5mqjCe9/VQg8KyuPxXHAuXth94bf6beAn4/TMdCIR9SmdM7rhumtLvxZeg3wDHCRux8GCM8Xhmqzvee5yoeqlDNHG83wJeC3gEJYvwA46cUb6sDMfk+/17B9NNQ/35/NXG0sta3ACPB/w7TWQ2bWTUyOA3d/F/h94B3gMMXf6XPE6xiou6gF/nndML2VmdkK4P8B/87dT81VtUqZL6K8ZZjZLwJH3f250uIqVX2ebcv5Z5MErgX+0N2vAc5SnF6ZzXJ+rxXC5wY7KE7DbAS6gduqVI3yMVB3UQv8SNww3cxSFMP+a+7+l6H4PTPbELZvAI6G8tne81zlfVXK52pjqX0EuMPM3gYeoTit8yVgjZlN3aWttN/T7zVsXw0c5/x/NsfmaGOpDQFD7v5MWH+U4n8AcTkObgLecvcRd88Cfwn8c+J1DNRd1AJ/2d8wPZwp8UfAq+7+P0s27QGmzrC4i+Lc/lT5Z8JZGtcDo+HP8H3ALWbWE0ZLt1CcizwMnDaz60NbnynbV7U2lpS73+vufe6+meLv8Hvu/ivA08Anq/SvtN+fDPU9lO8MZ3BsAbZR/KCy6nESXjNbG0vK3Y8Ah8zsilD0MeAV4nMcvANcb2ZdoX9T7z82x0BDNPtDhHo/KJ6t8DrFT+Dva3Z/FtH/n6H4J+SLwPPhcTvFucXvAm+E595Q34D7w/t9Cegv2devAQfC41dLyvuBl8NrvsK5b1xXbaPJP4+Pcu4sna0U/7EeAP4CSIfyjrB+IGzfWvL6+8L73E84C2Wu42S2Npr03q8GBsKx8FcUz7KJzXEA/FfgtdDHP6V4pk2sjoF6P3RpBRGRmIjalI6IiMxCgS8iEhMKfBGRmFDgi4jEhAJfRCQmFPgiIjGhwBcRiYn/DxbUQiv3a+O5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(np.divide(classifier_input, 9).flatten()))\n",
    "print(max(classifier_input.flatten()))\n",
    "print(min(classifier_input.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM training duration: 40.18838810920715 seconds\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC(class_weight='balanced', kernel='linear')\n",
    "\n",
    "start = time.time()\n",
    "SVM.fit(classifier_input, classifer_output)\n",
    "print('SVM training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF training duration: 153.7318708896637 seconds\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=256, max_depth=128, n_jobs=-1, warm_start=True)\n",
    "\n",
    "start = time.time()\n",
    "RF.fit(classifier_input, classifer_output)\n",
    "print('RF training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN training duration: 0.2558553218841553 seconds\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 1, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "KNN.fit(classifier_input, classifer_output)\n",
    "print('KNN training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATP_data = pd.DataFrame(pd.read_excel('./Data/V5_Run Input(1).xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_ATP = ATP_data\n",
    "trimmed_ATP['Current Job Title'] = trimmed_ATP['Current Job Title'].apply(preprocess_text)\n",
    "trimmed_ATP['Current Industry'] = trimmed_ATP['Current Industry'].apply(preprocess_text)\n",
    "trimmed_ATP['NOC code'] = trimmed_ATP['NOC code '].apply(lambda x: int(x.strip('\\''))).apply(first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    "trimmed_ATP.drop(columns = ['NOC code '], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_ATP['vote1'], trimmed_ATP['vote2'], trimmed_ATP['vote3'] = None, None, None\n",
    "trimmed_ATP[['vote1', 'vote2' ,'vote3']] = trimmed_ATP['Current Job Title'].apply(infer_and_vote)\n",
    "TPs = trimmed_ATP.apply(lambda row: int(row['NOC code']) in [row['vote1'], row['vote2'], row['vote3']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    23726\n",
       "True     16298\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d2v_embeddings = trimmed_ATP['Current Job Title'].apply(get_doc2vec_encoding)\n",
    "trimmed_ATP['doc2vec_embeddings'] = test_d2v_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized_embeddings = vectorize_embeddings(test_d2v_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_ATP['rf_pred'] = RF.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_ATP['knn_pred'] = KNN.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_ATP['svm_pred'] = SVM.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn_pred</th>\n",
       "      <th>svm_pred</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>NOC code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4154</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>212</td>\n",
       "      <td>4021</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4212</td>\n",
       "      <td>12</td>\n",
       "      <td>1221</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1121</td>\n",
       "      <td>422</td>\n",
       "      <td>1121</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>3236</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40019</th>\n",
       "      <td>8252</td>\n",
       "      <td>8221</td>\n",
       "      <td>6513</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40020</th>\n",
       "      <td>6421</td>\n",
       "      <td>6513</td>\n",
       "      <td>6421</td>\n",
       "      <td>6221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40021</th>\n",
       "      <td>1112</td>\n",
       "      <td>9536</td>\n",
       "      <td>1112</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40022</th>\n",
       "      <td>3216</td>\n",
       "      <td>8252</td>\n",
       "      <td>7302</td>\n",
       "      <td>4423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40023</th>\n",
       "      <td>9241</td>\n",
       "      <td>7521</td>\n",
       "      <td>9418</td>\n",
       "      <td>9461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40024 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       knn_pred  svm_pred  rf_pred  NOC code\n",
       "0            11      4154       11        11\n",
       "1           124       212     4021        11\n",
       "2          4212        12     1221        11\n",
       "3          1121       422     1121        11\n",
       "4            11      3236       11        11\n",
       "...         ...       ...      ...       ...\n",
       "40019      8252      8221     6513       821\n",
       "40020      6421      6513     6421      6221\n",
       "40021      1112      9536     1112       811\n",
       "40022      3216      8252     7302      4423\n",
       "40023      9241      7521     9418      9461\n",
       "\n",
       "[40024 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_ATP[['knn_pred', 'svm_pred', 'rf_pred', 'NOC code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN acc:0.35608634819108537, f1-macro:0.2246208258228614\n",
      "SVM acc:0.2453527883270038, f1-macro:0.1687395052553597\n",
      "RF acc:0.3016939836098341, f1-macro:0.2111054771740159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        trimmed_ATP['{}_pred'.format(classifier)], \n",
    "                                        trimmed_ATP['NOC code']\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        trimmed_ATP['{}_pred'.format(classifier)],\n",
    "                                        trimmed_ATP['NOC code'], average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm accuracy still tanks, potentially overfitting. the problem is too many output classes. \n",
    "# to mitigate, build hierarchical model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
