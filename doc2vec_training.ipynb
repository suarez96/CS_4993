{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scripts.TextPreprocessor import TextPreprocessor\n",
    "from scripts.OccupationPreprocessor import OccupationPreprocessor\n",
    "from scripts.TrainEngine import TrainEngine\n",
    "from scripts.Embedder import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if NOT working in colab\n",
    "data_dir = './data'\n",
    "\n",
    "# if working in colab\n",
    "# data_dir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all NOC webpage data into separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skill_type = pd.read_csv(os.path.join(data_dir, 'NOC_skilltype.csv'))\n",
    "df_major_group = pd.read_csv(os.path.join(data_dir, './NOC_majorgroup.csv'))\n",
    "df_minor_group = pd.read_csv(os.path.join(data_dir, './NOC_minorgroup.csv'))\n",
    "df = pd.read_csv(os.path.join(data_dir, './noc_data_get_byws_dealing_slash.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad missing digits from noc codes\n",
    "df['Noc_code'] = df['Noc_code'].apply(lambda x: '{0:0>4}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack all sample job titles in original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do once, if 'noc_code' column already dropped, except to skip action\n",
    "try:\n",
    "    df = df.apply(OccupationPreprocessor.extract_job_samples, axis = 1)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do same with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(OccupationPreprocessor.unpack_descriptions, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dict(OccupationPreprocessor.all_job_samples).items(), columns=['input', 'code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czAUrH4jBD0p"
   },
   "source": [
    "# Load ATP data for some train noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ATP data\n",
    "ATP_data = pd.DataFrame(pd.read_excel('./Data/V5_Run Input(1).xlsx'))\n",
    "\n",
    "# Clean codes: many show up as ''0011 or '0011\n",
    "ATP_data['code'] = ATP_data['NOC code '].apply(\n",
    "    lambda x: int(x.strip('\\''))\n",
    ").apply(OccupationPreprocessor.first_n_digits, args=(4,))\n",
    "\n",
    "ATP_data.drop(columns = ['NOC code '], inplace = True)\n",
    "\n",
    "ATP_data['input'] = ATP_data['Current Job Title']\n",
    "ATP_data.drop(columns = ['Current Job Title'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle ATP and split into train-val sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_ATP_df = ATP_data.sample(frac=1, random_state=42)\n",
    "\n",
    "# Sample size of ATP used for training \n",
    "ATP_train_size = 8000\n",
    "\n",
    "# Split  dataset \n",
    "ATP_data_train_set = shuffled_ATP_df[:ATP_train_size]\n",
    "ATP_data_test_set = shuffled_ATP_df[ATP_train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['input', 'code']]\n",
    "ATP_data_train_set = ATP_data_train_set[['input', 'code']]\n",
    "ATP_data_test_set = ATP_data_test_set[['input', 'code']]\n",
    "\n",
    "train_df = train_df.append(ATP_data_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the entire train and test input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_preprocessor = TextPreprocessor(strip_abbrev=True)\n",
    "# train_df['input'] = train_df['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train samples before dropping duplicates\", len(train_df))\n",
    "train_df = train_df.drop_duplicates()\n",
    "print(\"Train samples after dropping duplicates\", len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATP_data_test_set['input'] = ATP_data_test_set['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test samples before dropping duplicates\", len(ATP_data_test_set))\n",
    "# ATP_data_test_set = ATP_data_test_set.drop_duplicates()\n",
    "# print(\"Test samples after dropping duplicates\", len(ATP_data_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab sample to see if preprocessing worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(string):\n",
    "    try:\n",
    "        assert '.' not in string \\\n",
    "            and ',' not in string \\\n",
    "                and ')' not in string \\\n",
    "                    and '(' not in string \\\n",
    "                        and '-' not in string \\\n",
    "                            and ';' not in string \\\n",
    "                                and '/' not in string \\\n",
    "                                    and '\\'' not in string\n",
    "    except AssertionError:\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['input'].apply(check)\n",
    "display(train_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Doc2vec code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRIAL_NAME = 'trial_9'\n",
    "\n",
    "doc2vec_params = dict(\n",
    "epochs = 4096, # training cycles\n",
    "vec_size = 32, # specific to doc2vec, size of the output vector\n",
    "alpha = 0.001, # learning rate\n",
    "window = 3,\n",
    "min_count = 2,\n",
    "min_alpha = 0.00025\n",
    ")\n",
    "\n",
    "embedder = Embedder(train_data = train_df,\n",
    "                    corpus_column = 'input',\n",
    "                    d2v_trial_name=TRIAL_NAME, \n",
    "                    d2v_params=doc2vec_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.train_doc2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.load_doc2vec_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedder.train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_occupations = ['doctor', 'athlete', 'member of parliament',\n",
    "                    'teacher', 'researcher', 'registered nurse', \n",
    "                    'CUSTOMER SERVICE', 'MANAGER OF CLEANING BUSINESS',\n",
    "                   'CAREGIVER', 'Farm Boss']\n",
    "\n",
    "for occ in test_occupations: \n",
    "    occ = TextPreprocessor.preprocess_text(occ)\n",
    "    print(Embedder.infer_and_vote(occ, embedder, verbose=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 131364,
     "status": "ok",
     "timestamp": 1602282557549,
     "user": {
      "displayName": "Augusto Suarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-L8Zz0VgrA4IkXJW-J6TWQaOde13RXj7wSR0P=s64",
      "userId": "05858047290514616239"
     },
     "user_tz": 180
    },
    "id": "K-aKuFF9BD0q",
    "outputId": "bb6f7b18-78e8-4be0-a74c-cfdc64c6e227"
   },
   "outputs": [],
   "source": [
    "embedder.train_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply embeddings to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'input' in embedder.train_df.columns and 'code' in embedder.train_df.columns, \"Make sure train dataframe has 'input' column and 'code' column\"\n",
    "train_d2v_embeddings = train_df['input'].apply(\n",
    "    Embedder.get_doc2vec_embeddings, args=(embedder,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CODE_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_train_vectors = Embedder.vectorize_embeddings(train_d2v_embeddings)\n",
    "tfidf_train_vectors = Embedder.get_tfidf_embeddings(embedder, train_df['input'])\n",
    "\n",
    "assert d2v_train_vectors.shape[0] == tfidf_train_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_train_vectors # d2v_train_vectors\n",
    "y_train = np.array(train_df['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d2v_embeddings = ATP_data_test_set['input'].apply(\n",
    "    Embedder.get_doc2vec_embeddings, args=(embedder,)\n",
    ")\n",
    "d2v_test_vectors = Embedder.vectorize_embeddings(test_d2v_embeddings)\n",
    "tfidf_test_vectors = Embedder.get_tfidf_embeddings(embedder, ATP_data_test_set['input'])\n",
    "\n",
    "assert d2v_test_vectors.shape[0] == tfidf_test_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf_test_vectors # d2v_test_vectors\n",
    "y_test = np.array(ATP_data_test_set['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build preliminary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM = SVC(class_weight='balanced', kernel='linear')\n",
    "\n",
    "start = time.time()\n",
    "SVM.fit(X_train, y_train)\n",
    "print('SVM training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=256, max_depth=128, n_jobs=-1, warm_start=True)\n",
    "\n",
    "start = time.time()\n",
    "RF.fit(X_train, y_train)\n",
    "print('RF training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 1, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "KNN.fit(X_train, y_train)\n",
    "print('KNN training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_cw66gEMiQU"
   },
   "source": [
    "# Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWmPefoPEO_c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svm_pred = SVM.predict(X_test)\n",
    "print('SVM prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggSfm8uHERlp"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf_pred = RF.predict(X_test)\n",
    "print('RF prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLvftUL7BD1c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "knn_pred = KNN.predict(X_test)\n",
    "print('KNN prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKhah7vkBD1h"
   },
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvm3AYkfBD1i",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "tfidf_test_df = pd.DataFrame({\n",
    "    'svm_pred':svm_pred,\n",
    "    'rf_pred':rf_pred,\n",
    "    'knn_pred':knn_pred,\n",
    "    'code':y_test\n",
    "})\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)], \n",
    "                                        y_test\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)],\n",
    "                                        y_test, average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get this inside the embedder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cWEUSmGBD1m"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def ensemble_predict(row):\n",
    "\n",
    "    # find majority vote for all methods, :-1 drops ground truth column\n",
    "    votes = Counter(row[['rf_pred','svm_pred','knn_pred']]).most_common(1)\n",
    "    \n",
    "    # take svm as tie-breaker because CURRENTLY most accurate\n",
    "    winning_class, highest_num_votes = votes[0]\n",
    "    return winning_class\n",
    "    return row['svm_pred'] if highest_num_votes < 2 else winning_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvvRbrgABD1q"
   },
   "outputs": [],
   "source": [
    "tfidf_test_df['p_all'] = tfidf_test_df.drop(columns=['code']).apply(ensemble_predict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ensemble acc:{}, f1:{}'.format(accuracy_score(tfidf_test_df['p_all'], y_test), \n",
    "                                      f1_score(tfidf_test_df['p_all'], y_test, average = 'macro')))\n",
    "display(tfidf_test_df.iloc[:20][['p_all','code']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Adjust doc2vec testing to work with new code. Also get ensemble vote working for tfidf predictor\n",
    "# Is preprocessing hurting the TFIDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df = ATP_data_test_set.sample(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df['vote1'], doc2vec_test_df['vote2'], doc2vec_test_df['vote3'] = None, None, None\n",
    "doc2vec_test_df[['vote1', 'vote2' ,'vote3']] = doc2vec_test_df['input'].apply(Embedder.infer_and_vote, args = (embedder, False,))\n",
    "TPs = doc2vec_test_df.apply(lambda row: int(row['code']) in [row['vote1'], row['vote2'], row['vote3']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedder.infer_doc2vec('instructor')\n",
    "Embedder.get_tfidf_embeddings(embedder, 'instructor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['group_title'].str.contains('instructor')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATP_data_test_set.loc[ATP_data_test_set['input'] == str('instructor teacher')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TPs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d2v_embeddings = doc2vec_test_df['input'].apply(get_doc2vec_embeddings, args=(embedder,))\n",
    "doc2vec_test_df['doc2vec_embeddings'] = test_d2v_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized_embeddings = vectorize_embeddings(test_d2v_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['rf_pred'] = RF.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['knn_pred'] = KNN.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['svm_pred'] = SVM.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df[['knn_pred', 'svm_pred', 'rf_pred', 'code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        doc2vec_test_df['{}_pred'.format(classifier)], \n",
    "                                        doc2vec_test_df['code']\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        doc2vec_test_df['{}_pred'.format(classifier)],\n",
    "                                        doc2vec_test_df['code'], average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm accuracy still tanks, potentially overfitting. the problem is too many output classes. \n",
    "# to mitigate, build hierarchical model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
