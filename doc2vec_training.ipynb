{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gradlab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scripts.TextPreprocessor import TextPreprocessor\n",
    "from scripts.OccupationPreprocessor import OccupationPreprocessor\n",
    "from scripts.TrainEngine import TrainEngine\n",
    "from scripts.Embedder import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if NOT working in colab\n",
    "data_dir = './data'\n",
    "\n",
    "# if working in colab\n",
    "# data_dir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all NOC webpage data into separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skill_type = pd.read_csv(os.path.join(data_dir, 'NOC_skilltype.csv'))\n",
    "df_major_group = pd.read_csv(os.path.join(data_dir, './NOC_majorgroup.csv'))\n",
    "df_minor_group = pd.read_csv(os.path.join(data_dir, './NOC_minorgroup.csv'))\n",
    "df = pd.read_csv(os.path.join(data_dir, './noc_data_get_byws_dealing_slash.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad missing digits from noc codes\n",
    "df['Noc_code'] = df['Noc_code'].apply(lambda x: '{0:0>4}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_character(string, char):\n",
    "\n",
    "    occurrences = 0\n",
    "    for occupation in string.split(';'):\n",
    "        if char in occupation:\n",
    "            print(occupation)\n",
    "            occurrences += 1\n",
    "\n",
    "    if char in TextPreprocessor.char_occurences:\n",
    "        TextPreprocessor.char_occurences[char] += occurrences\n",
    "    else:\n",
    "        TextPreprocessor.char_occurences[char] = occurrences\n",
    "\n",
    "# df.sample(500)['job_title'].apply(find_character, args=('(',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack all sample job titles in original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do once, if 'noc_code' column already dropped, except to skip action\n",
    "try:\n",
    "    df = df.apply(OccupationPreprocessor.extract_job_samples, axis = 1)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do same with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(OccupationPreprocessor.unpack_descriptions, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dict(OccupationPreprocessor.all_job_samples).items(), columns=['input', 'code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czAUrH4jBD0p"
   },
   "source": [
    "# Load ATP data for some train noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ATP data\n",
    "ATP_data = pd.DataFrame(pd.read_excel('./Data/V5_Run Input(1).xlsx'))\n",
    "\n",
    "# Clean codes: many show up as ''0011 or '0011\n",
    "ATP_data['code'] = ATP_data['NOC code '].apply(\n",
    "    lambda x: int(x.strip('\\''))\n",
    ").apply(OccupationPreprocessor.first_n_digits, args=(4,))\n",
    "\n",
    "ATP_data.drop(columns = ['NOC code '], inplace = True)\n",
    "\n",
    "ATP_data['input'] = ATP_data['Current Job Title']\n",
    "ATP_data.drop(columns = ['Current Job Title'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle ATP and split into train-val sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_ATP_df = ATP_data.sample(frac=1, random_state=42)\n",
    "\n",
    "# Sample size of ATP used for training \n",
    "ATP_train_size = 8000\n",
    "\n",
    "# Split  dataset \n",
    "ATP_data_train_df = shuffled_ATP_df[:ATP_train_size]\n",
    "test_df = shuffled_ATP_df[ATP_train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['input', 'code']]\n",
    "ATP_data_train_df = ATP_data_train_df[['input', 'code']]\n",
    "test_df = test_df[['input', 'code']]\n",
    "\n",
    "train_df = train_df.append(ATP_data_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Industry</th>\n",
       "      <th>code</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>RECEPTION, ACCOUNTING, BOOKINGS, PARTS ORDERS,...</td>\n",
       "      <td>1221</td>\n",
       "      <td>OFFICE ADMINISTRATOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24582</th>\n",
       "      <td>HOUSING AND SUPPLEMENT PROGRAMS</td>\n",
       "      <td>423</td>\n",
       "      <td>HOUSING MANAGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18410</th>\n",
       "      <td>ROOFING</td>\n",
       "      <td>7291</td>\n",
       "      <td>ROOF ESTIMATOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27460</th>\n",
       "      <td>RANCH WORK</td>\n",
       "      <td>821</td>\n",
       "      <td>OWNER RANCHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12522</th>\n",
       "      <td>SCHOOL</td>\n",
       "      <td>4032</td>\n",
       "      <td>TEACHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>TAX PREPARATION AND BOOKKEEPING</td>\n",
       "      <td>1431</td>\n",
       "      <td>TAX PREPARER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>HEALTH CARE AID (CARE FOR ELDERLY)</td>\n",
       "      <td>3413</td>\n",
       "      <td>PERSONAL SUPPORT AID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>CLERICAL, ADMINISTRATION, ADVISOR, CONFLICT RE...</td>\n",
       "      <td>1121</td>\n",
       "      <td>HUMAN RESOURCE OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>PRIVATE SCHOOL</td>\n",
       "      <td>422</td>\n",
       "      <td>ENROLLMENT COORDINATOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>REAL ESTATE</td>\n",
       "      <td>6232</td>\n",
       "      <td>REALTOR, PROPERTY MANAGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32024 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Current Industry  code  \\\n",
       "3507   RECEPTION, ACCOUNTING, BOOKINGS, PARTS ORDERS,...  1221   \n",
       "24582                    HOUSING AND SUPPLEMENT PROGRAMS   423   \n",
       "18410                                            ROOFING  7291   \n",
       "27460                                         RANCH WORK   821   \n",
       "12522                                             SCHOOL  4032   \n",
       "...                                                  ...   ...   \n",
       "6265                     TAX PREPARATION AND BOOKKEEPING  1431   \n",
       "11284                 HEALTH CARE AID (CARE FOR ELDERLY)  3413   \n",
       "38158  CLERICAL, ADMINISTRATION, ADVISOR, CONFLICT RE...  1121   \n",
       "860                                       PRIVATE SCHOOL   422   \n",
       "15795                                        REAL ESTATE  6232   \n",
       "\n",
       "                           input  \n",
       "3507        OFFICE ADMINISTRATOR  \n",
       "24582            HOUSING MANAGER  \n",
       "18410             ROOF ESTIMATOR  \n",
       "27460              OWNER RANCHER  \n",
       "12522                    TEACHER  \n",
       "...                          ...  \n",
       "6265                TAX PREPARER  \n",
       "11284       PERSONAL SUPPORT AID  \n",
       "38158     HUMAN RESOURCE OFFICER  \n",
       "860       ENROLLMENT COORDINATOR  \n",
       "15795  REALTOR, PROPERTY MANAGER  \n",
       "\n",
       "[32024 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATP_data.iloc[test_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the entire train and test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_train_df = train_df.copy()\n",
    "# tfidf_test_df = test_df.copy()\n",
    "# doc2vec_train_df = train_df.copy()\n",
    "# doc2vec_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor(strip_abbrev=True)\n",
    "train_df['input'] = train_df['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples before dropping duplicates 37745\n",
      "Train samples after dropping duplicates 33432\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples before dropping duplicates\", len(train_df))\n",
    "train_df = train_df.drop_duplicates()\n",
    "print(\"Train samples after dropping duplicates\", len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['input'] = test_df['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples before dropping duplicates 32024\n",
      "Test samples after dropping duplicates 14327\n"
     ]
    }
   ],
   "source": [
    "print(\"Test samples before dropping duplicates\", len(test_df))\n",
    "test_df = test_df.drop_duplicates()\n",
    "print(\"Test samples after dropping duplicates\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc2vec_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3cda3fc8a2ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc2vec_test_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc2vec_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "doc2vec_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_train_df.to_csv('./data/tfidf_train_df.csv', index=False)\n",
    "# tfidf_test_df.to_csv('./data/tfidf_test_df.csv', index=False)\n",
    "# doc2vec_train_df.to_csv('./data/doc2vec_train_df.csv', index=False)\n",
    "# doc2vec_test_df.to_csv('./data/doc2vec_test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab sample to see if preprocessing worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(string):\n",
    "    try:\n",
    "        assert '.' not in string \\\n",
    "            and ',' not in string \\\n",
    "                and ')' not in string \\\n",
    "                    and '(' not in string \\\n",
    "                        and '-' not in string \\\n",
    "                            and ';' not in string \\\n",
    "                                and '/' not in string \\\n",
    "                                    and '\\'' not in string\n",
    "    except AssertionError:\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['input'].apply(check)\n",
    "display(train_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Doc2vec code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRIAL_NAME = 'trial_11'\n",
    "\n",
    "doc2vec_params = dict(\n",
    "epochs = 6144, # training cycles\n",
    "vec_size = 64, # specific to doc2vec, size of the output vector\n",
    "alpha = 0.001, # learning rate\n",
    "window = 3,\n",
    "min_count = 2,\n",
    "min_alpha = 0.00025\n",
    ")\n",
    "\n",
    "embedder = Embedder(\n",
    "    d2v_trial_name=TRIAL_NAME,\n",
    "    d2v_params=doc2vec_params,\n",
    "    train_data = train_df,\n",
    "    corpus_column = 'input',\n",
    "    infer_params = {\n",
    "        'steps':2048,\n",
    "        'alpha':0.03\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.train_doc2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.load_doc2vec_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextPreprocessor.abbreviations_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_occupations = ['doctor', 'athlete', 'member of parliament',\n",
    "                    'teacher', 'researcher', 'registered nurse', \n",
    "                    'CUSTOMER SERVICE', 'MANAGER OF CLEANING BUSINESS',\n",
    "                   'CAREGIVER', 'Farm Boss']\n",
    "\n",
    "for occ in test_occupations: \n",
    "    occ = TextPreprocessor.preprocess_text(occ)\n",
    "    print(embedder.infer_and_vote(occ, verbose=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 131364,
     "status": "ok",
     "timestamp": 1602282557549,
     "user": {
      "displayName": "Augusto Suarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-L8Zz0VgrA4IkXJW-J6TWQaOde13RXj7wSR0P=s64",
      "userId": "05858047290514616239"
     },
     "user_tz": 180
    },
    "id": "K-aKuFF9BD0q",
    "outputId": "bb6f7b18-78e8-4be0-a74c-cfdc64c6e227"
   },
   "outputs": [],
   "source": [
    "embedder.train_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply embeddings to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'input' in embedder.train_df.columns and 'code' in embedder.train_df.columns, \"Make sure train dataframe has 'input' column and 'code' column\"\n",
    "train_d2v_embeddings = train_df['input'].apply(\n",
    "    Embedder.get_doc2vec_embeddings, args=(embedder,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vec_train_df[doc2vec_train_df.code == 3012])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CODE_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2v_train_vectors = Embedder.vectorize_embeddings(train_d2v_embeddings)\n",
    "tfidf_train_vectors = Embedder.get_tfidf_embeddings(embedder, train_df['input'])\n",
    "\n",
    "# assert d2v_train_vectors.shape[0] == tfidf_train_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_train_vectors # d2v_train_vectors\n",
    "y_train = np.array(train_df['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_d2v_embeddings = test_df['input'].apply(\n",
    "#     Embedder.get_doc2vec_embeddings, args=(embedder,)\n",
    "# )\n",
    "# d2v_test_vectors = Embedder.vectorize_embeddings(test_d2v_embeddings)\n",
    "tfidf_test_vectors = Embedder.get_tfidf_embeddings(embedder, test_df['input'])\n",
    "\n",
    "# assert d2v_test_vectors.shape[0] == tfidf_test_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf_test_vectors # d2v_test_vectors\n",
    "y_test = np.array(test_df['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build preliminary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM = SVC(class_weight='balanced', kernel='linear')\n",
    "\n",
    "start = time.time()\n",
    "SVM.fit(X_train, y_train)\n",
    "print('SVM training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=64, max_depth=128, n_jobs=-1, warm_start=True)\n",
    "\n",
    "start = time.time()\n",
    "RF.fit(X_train, y_train)\n",
    "print('RF training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 1, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "KNN.fit(X_train, y_train)\n",
    "print('KNN training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "LR.fit(X_train, y_train)\n",
    "print('LR training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_cw66gEMiQU"
   },
   "source": [
    "# Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWmPefoPEO_c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svm_pred = SVM.predict(X_test)\n",
    "print('SVM prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggSfm8uHERlp"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf_pred = RF.predict(X_test)\n",
    "print('RF prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLvftUL7BD1c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "knn_pred = KNN.predict(X_test)\n",
    "print('KNN prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lr_pred = LR.predict(X_test)\n",
    "print('LR prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKhah7vkBD1h"
   },
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvm3AYkfBD1i",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "tfidf_test_df = pd.DataFrame({\n",
    "    'svm_pred':svm_pred,\n",
    "#     'rf_pred':rf_pred,\n",
    "    'knn_pred':knn_pred,\n",
    "    'lr_pred':lr_pred,\n",
    "    'code':y_test\n",
    "})\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn', 'svm', 'lr']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)], \n",
    "                                        y_test\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)],\n",
    "                                        y_test, average = 'macro')\n",
    "                                   )\n",
    "     )\n",
    "    \n",
    "# KNN acc:0.476, f1-macro:0.3900045178082561\n",
    "# SVM acc:0.5, f1-macro:0.4011703553848126\n",
    "# RF acc:0.42, f1-macro:0.3912001209939354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get this inside the embedder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cWEUSmGBD1m"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def ensemble_predict(row, predictor_cols, default_predictor):\n",
    "\n",
    "    # find majority vote for all methods, :-1 drops ground truth column\n",
    "    votes = Counter(row[predictor_cols]).most_common(1)\n",
    "    \n",
    "    # take svm as tie-breaker because CURRENTLY most accurate\n",
    "    winning_class, highest_num_votes = votes[0]\n",
    "    return winning_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvvRbrgABD1q"
   },
   "outputs": [],
   "source": [
    "tfidf_test_df['p_all'] = tfidf_test_df.apply(ensemble_predict, axis = 1, args = (\n",
    "    ['svm_pred','knn_pred', 'lr_pred'], 'svm_pred',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('TFIDF_SVM_KNN_LR.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'SVM':SVM,\n",
    "        'KNN':KNN,\n",
    "        'LR':LR\n",
    "#         'RF':RF\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ensemble acc:{}, f1:{}'.format(accuracy_score(tfidf_test_df['p_all'], y_test), \n",
    "                                      f1_score(tfidf_test_df['p_all'], y_test, average = 'macro')))\n",
    "display(tfidf_test_df.iloc[:20][['p_all','code']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Adjust doc2vec testing to work with new code. Also get ensemble vote working for tfidf predictor\n",
    "# Is preprocessing hurting the TFIDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df = test_df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick exact match test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exact_match(row):\n",
    "    exact_matches = train_df.loc[train_df['input'] == str(row)]\n",
    "    code = exact_matches['code'].values[0] if len(exact_matches) == 1 else -1\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df['exact_match'] = doc2vec_test_df['input'].apply(check_exact_match)\n",
    "doc2vec_test_df['exact_matches_TP'] = doc2vec_test_df.apply(lambda row: row['exact_match'] == row['code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df['exact_matches_TP'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial for tuning infer params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_test_df['vote1'], doc2vec_test_df['vote2'], doc2vec_test_df['vote3'] = None, None, None\n",
    "votes = []\n",
    "for row in doc2vec_test_df.itertuples():\n",
    "    if row.exact_match == -1:\n",
    "        votes.append(embedder.infer_and_vote(row.input, verbose=False))\n",
    "    else:\n",
    "        votes.append(pd.Series([-1, -1, -1]))\n",
    "        \n",
    "doc2vec_test_df[['vote1', 'vote2', 'vote3']] = votes\n",
    "TPs = doc2vec_test_df.apply(lambda row: int(row['code']) in [row['vote1'], row['vote2'], row['vote3'], row['exact_match']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(TPs.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3077/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d2v_embeddings = doc2vec_test_df['input'].apply(get_doc2vec_embeddings, args=(embedder,))\n",
    "doc2vec_test_df['doc2vec_embeddings'] = test_d2v_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized_embeddings = vectorize_embeddings(test_d2v_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['rf_pred'] = RF.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['knn_pred'] = KNN.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['svm_pred'] = SVM.predict(vectorized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df[['knn_pred', 'svm_pred', 'rf_pred', 'code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        doc2vec_test_df['{}_pred'.format(classifier)], \n",
    "                                        doc2vec_test_df['code']\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        doc2vec_test_df['{}_pred'.format(classifier)],\n",
    "                                        doc2vec_test_df['code'], average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm accuracy still tanks, potentially overfitting. the problem is too many output classes. \n",
    "# to mitigate, build hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
