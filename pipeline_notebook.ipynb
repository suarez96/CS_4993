{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gradlab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from scripts.Embedder import Embedder, tfidfEmbedder\n",
    "from scripts.OccupationPreprocessor import OccupationPreprocessor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_dig_tfidf_clfs.pkl', 'rb') as f:\n",
    "    clf1 = pickle.load(f)\n",
    "    \n",
    "with open('second_third_fourth_dig_tfidf_clfs.pkl', 'rb') as f2:\n",
    "    clf2 = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_FILE == 0:\n",
    "    tfidf_test_set = OccupationPreprocessor.prepare_df(\n",
    "        './Data/ATP_gold_standard.xlsx',\n",
    "        input_column='CURRENT_JOB_TITLE',\n",
    "        code_column='NOC code by PATH',\n",
    "        n_digits=4\n",
    "    )\n",
    "    \n",
    "    NOCv5 = OccupationPreprocessor.prepare_df(\n",
    "        './Data/ATP_gold_standard.xlsx',\n",
    "        input_column='NOC code by PATH',\n",
    "        code_column='V5_NOC',\n",
    "        n_digits=4\n",
    "    )\n",
    "    \n",
    "    NOCv6 = OccupationPreprocessor.prepare_df(\n",
    "        './Data/ATP_gold_standard.xlsx',\n",
    "        input_column='NOC code by PATH',\n",
    "        code_column='V6_NOC',\n",
    "        n_digits=4\n",
    "    )\n",
    "    \n",
    "elif TEST_FILE == 1:\n",
    "    tfidf_test_set = pd.DataFrame(\n",
    "        pd.read_csv('./Data/tfidf_test_set.csv')\n",
    "    )\n",
    "    \n",
    "tfidf_train_set = pd.DataFrame(\n",
    "    pd.read_csv('./Data/tfidf_train_set.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./vectorizer.joblib\n"
     ]
    }
   ],
   "source": [
    "embedder = tfidfEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500 if TEST_FILE == 0 else 500\n",
    "sample_pipeline_df = tfidf_test_set.sample(sample_size).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pipeline_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check exact matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_vectors = embedder.embed(sample_pipeline_df['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "tfidf_test_df = pd.DataFrame({\n",
    "    'svm_pred':clf1['SVM'].predict(tfidf_test_vectors),\n",
    "    'rf_pred':clf1['RF'].predict(tfidf_test_vectors),\n",
    "    'knn_pred':clf1['KNN'].predict(tfidf_test_vectors),\n",
    "    'code':sample_pipeline_df['code'].astype(str)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['exact_match'] = sample_pipeline_df['input'].apply(embedder.check_exact_match, args=(embedder.train_database,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['p_all'] = tfidf_test_df.apply(tfidfEmbedder.ensemble_predict, axis = 1, args = (\n",
    "    ['rf_pred','svm_pred','knn_pred'], 'svm_pred',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['vectors'] = tfidf_test_vectors.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in pipeline.py\n",
    "def pipeline(row):\n",
    "    np_array = np.array(row['vectors']).reshape(1, -1)\n",
    "    p_1 = row['p_all']\n",
    "    row['svm_pred_234'] = clf2[p_1]['SVM'].predict(np_array)[0]\n",
    "    row['rf_pred_234'] = clf2[p_1]['RF'].predict(np_array)[0]\n",
    "    row['knn_pred_234'] = clf2[p_1]['KNN'].predict(np_array)[0]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tfidf_test_df = tfidf_test_df.apply(pipeline, axis = 1)\n",
    "print('time to predict on {} samples: {} seconds'.format(sample_size, np.round(time.time()-start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['p_all_234'] = tfidf_test_df.apply(tfidfEmbedder.ensemble_predict, axis = 1, args = (\n",
    "    ['svm_pred_234','rf_pred_234','knn_pred_234'], 'knn_pred_234',\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance w/o exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        tfidf_test_df['{}_pred_234'.format(classifier)].astype(int), \n",
    "                                        tfidf_test_df['code'].astype(int)\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        tfidf_test_df['{}_pred_234'.format(classifier)].astype(int),\n",
    "                                        tfidf_test_df['code'].astype(int), average = 'macro')\n",
    "                                   )\n",
    "     )\n",
    "print('Ensemble metrics total. Accuracy:{}, f1:{}\\n'.format(\n",
    "    accuracy_score(tfidf_test_df['p_all_234'].astype(int), tfidf_test_df['code'].astype(int)), \n",
    "    f1_score(tfidf_test_df['p_all_234'].astype(int), tfidf_test_df['code'].astype(int), average = 'macro')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With exact match added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['Hybrid_pred_exact_match'] = tfidf_test_df.apply(\n",
    "    lambda row : row['p_all_234'] if row['exact_match'] == -1 else row['exact_match'], axis = 1\n",
    ")\n",
    "print('Ensemble metrics after checking for exact match total. Accuracy:{}, f1:{}\\n'.format(\n",
    "    accuracy_score(tfidf_test_df['Hybrid_pred_exact_match'].astype(int), tfidf_test_df['code'].astype(int)), \n",
    "    f1_score(tfidf_test_df['Hybrid_pred_exact_match'].astype(int), tfidf_test_df['code'].astype(int), average = 'macro')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_noc_double_codes(row, column):\n",
    "    if ',' in row[column]:\n",
    "        row[column] = str(row[column].strip('\\'').split(',')[1])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_FILE == 0:\n",
    "    NOCv5 = NOCv5.apply(clean_noc_double_codes, axis =1 , args = ('input',))\n",
    "    NOCv6 = NOCv6.apply(clean_noc_double_codes, axis =1 , args = ('input',))\n",
    "    print('NOCv5 Ensemble metrics total. Accuracy:{}, f1:{}\\n'.format(\n",
    "        accuracy_score(NOCv5['input'].astype(int), NOCv5['code'].astype(int)), \n",
    "        f1_score(NOCv5['input'].astype(int), NOCv5['code'].astype(int), average = 'macro')\n",
    "    ))\n",
    "    print('NOCv6 Ensemble metrics total. Accuracy:{}, f1:{}\\n'.format(\n",
    "        accuracy_score(NOCv6['input'].astype(int), NOCv6['code'].astype(int)), \n",
    "        f1_score(NOCv6['input'].astype(int), NOCv6['code'].astype(int), average = 'macro')\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df.drop_columns(['vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
