{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\augus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scripts.TextPreprocessor import TextPreprocessor\n",
    "from scripts.OccupationPreprocessor import OccupationPreprocessor\n",
    "from scripts.TrainEngine import TrainEngine\n",
    "from scripts.Embedder import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/noc_data_get_byws_dealing_slash.csv')\n",
    "df = df.apply(OccupationPreprocessor.extract_job_samples, axis = 1)\n",
    "train_df = pd.DataFrame(dict(OccupationPreprocessor.all_job_samples).items(), columns=['input', 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input unprocessed by default\n"
     ]
    }
   ],
   "source": [
    "# Load ATP data\n",
    "ATP_data = OccupationPreprocessor.prepare_df('./Data/V5_Run Input(1).xlsx', \n",
    "                                             input_column='Current Job Title',\n",
    "                                            code_column='NOC code ',\n",
    "                                             n_digits=4\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle ATP and split into train-val sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_ATP_df = ATP_data.sample(frac=1, random_state=42)\n",
    "\n",
    "# Sample size of ATP used for training \n",
    "ATP_train_size = 8000\n",
    "\n",
    "# Split  dataset \n",
    "ATP_data_train_set = shuffled_ATP_df[:ATP_train_size]\n",
    "ATP_data_test_set = shuffled_ATP_df[ATP_train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.append(ATP_data_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncleaned_train_df = train_df.copy() # for tfidf, note: that tfidf lowercases regardless\n",
    "cleaned_train_df = train_df.copy() # for doc2vec\n",
    "cleaned_train_df['input'] = cleaned_train_df['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulted doc2vec param: dm=1\n"
     ]
    }
   ],
   "source": [
    "TRIAL_NAME = 'trial_11'\n",
    "\n",
    "doc2vec_params = dict(\n",
    "epochs = 6144, # training cycles\n",
    "vec_size = 64, # specific to doc2vec, size of the output vector\n",
    "alpha = 0.001, # learning rate\n",
    "window = 3,\n",
    "min_count = 2,\n",
    "min_alpha = 0.00025\n",
    ")\n",
    "\n",
    "embedder = Embedder(\n",
    "    d2v_trial_name=TRIAL_NAME,\n",
    "    d2v_params=doc2vec_params,\n",
    "    train_data = uncleaned_train_df,\n",
    "    corpus_column = 'input',\n",
    "    infer_params = {\n",
    "        'steps':2048,\n",
    "        'alpha':0.03\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF training vector shape (37745, 2633)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<37745x2633 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 108442 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.train_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply embeddings to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CODE_LENGTH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_vectors = Embedder.get_tfidf_embeddings(embedder, uncleaned_train_df['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_train, get the column by which we separate classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = tfidf_train_vectors\n",
    "y_train = train_df['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_digit = train_df['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(1,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_vectors = Embedder.get_tfidf_embeddings(embedder, ATP_data_test_set['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf_test_vectors\n",
    "y_test = np.array(ATP_data_test_set['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_classifiers = {\n",
    "    # keys are first level outputs, value is a dictionary with keys 'svm', 'knn', 'rf' and \n",
    "}\n",
    "# set all classifiers to empty\n",
    "for key in first_digit.unique():\n",
    "    second_level_classifiers[key] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '00', '00', ..., '30', '21', '72'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM training duration: 0.4592933654785156 seconds\n",
      "RF training duration: 1.9123950004577637 seconds\n",
      "KNN training duration: 0.003981590270996094 seconds\n",
      "SVM training duration: 0.279252290725708 seconds\n",
      "RF training duration: 1.5468008518218994 seconds\n",
      "KNN training duration: 0.003988742828369141 seconds\n",
      "SVM training duration: 0.1077125072479248 seconds\n",
      "RF training duration: 0.9747607707977295 seconds\n",
      "KNN training duration: 0.004026174545288086 seconds\n",
      "SVM training duration: 0.06254863739013672 seconds\n",
      "RF training duration: 0.8690054416656494 seconds\n",
      "KNN training duration: 0.002022266387939453 seconds\n",
      "SVM training duration: 0.17053580284118652 seconds\n",
      "RF training duration: 1.304694414138794 seconds\n",
      "KNN training duration: 0.004025697708129883 seconds\n",
      "SVM training duration: 0.05086398124694824 seconds\n",
      "RF training duration: 0.7423279285430908 seconds\n",
      "KNN training duration: 0.002997875213623047 seconds\n",
      "SVM training duration: 0.20246028900146484 seconds\n",
      "RF training duration: 1.4689247608184814 seconds\n",
      "KNN training duration: 0.0039937496185302734 seconds\n",
      "SVM training duration: 0.7562940120697021 seconds\n",
      "RF training duration: 2.7124528884887695 seconds\n",
      "KNN training duration: 0.010974407196044922 seconds\n",
      "SVM training duration: 0.07280468940734863 seconds\n",
      "RF training duration: 0.8938791751861572 seconds\n",
      "KNN training duration: 0.002991199493408203 seconds\n",
      "SVM training duration: 2.400285243988037 seconds\n",
      "RF training duration: 5.442460060119629 seconds\n",
      "KNN training duration: 0.014960050582885742 seconds\n"
     ]
    }
   ],
   "source": [
    "for key in first_digit.unique():\n",
    "\n",
    "    print(\"Training for\", key)\n",
    "    filtered_X_train = Embedder.get_tfidf_embeddings(embedder, uncleaned_train_df.loc[first_digit == key]['input'])\n",
    "    filtered_y_train = pd.Series(y_train).loc[first_digit == key]\n",
    "\n",
    "    # --------------------SVM\n",
    "    SVM = SVC(class_weight='balanced', kernel='linear')\n",
    "\n",
    "    start = time.time()\n",
    "    SVM.fit(filtered_X_train, filtered_y_train)\n",
    "    print('SVM training duration: {} seconds'.format(time.time()-start))\n",
    "    \n",
    "    # save to dict\n",
    "    second_level_classifiers[key]['SVM'] = SVM\n",
    "    \n",
    "    # --------------------RF\n",
    "    RF = RandomForestClassifier(n_estimators=256, max_depth=128, n_jobs=-1, warm_start=True)\n",
    "\n",
    "    start = time.time()\n",
    "    RF.fit(filtered_X_train, filtered_y_train)\n",
    "    print('RF training duration: {} seconds'.format(time.time()-start))\n",
    "    \n",
    "    # save to dict\n",
    "    second_level_classifiers[key]['RF'] = RF\n",
    "    \n",
    "    # --------------------KNN\n",
    "    KNN = KNeighborsClassifier(n_neighbors = 4, n_jobs=-1)\n",
    "\n",
    "    start = time.time()\n",
    "    KNN.fit(filtered_X_train, filtered_y_train)\n",
    "    print('KNN training duration: {} seconds'.format(time.time()-start))\n",
    "    \n",
    "    # save to dict\n",
    "    second_level_classifiers[key]['KNN'] = KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '1': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '2': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '3': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '4': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '5': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '6': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '7': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '8': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')},\n",
       " '9': {'SVM': SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=128, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=256,\n",
       "                         n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=True),\n",
       "  'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                       weights='uniform')}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_level_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_cw66gEMiQU"
   },
   "source": [
    "# Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JLvftUL7BD1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN prediction duration on 32024 samples: 39.22178316116333 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svm_pred = SVM.predict(X_test)\n",
    "print('SVM prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "rf_pred = RF.predict(X_test)\n",
    "print('RF prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "knn_pred = KNN.predict(X_test)\n",
    "print('KNN prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "tfidf_test_df = pd.DataFrame({\n",
    "    'svm_pred':svm_pred,\n",
    "    'rf_pred':rf_pred,\n",
    "    'knn_pred':knn_pred,\n",
    "    'code':y_test\n",
    "})\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)], \n",
    "                                        y_test\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)],\n",
    "                                        y_test, average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKhah7vkBD1h"
   },
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hvm3AYkfBD1i",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN acc:0.7903135148638522, f1-macro:0.7178526487613797\n",
      "SVM acc:0.809580314763927, f1-macro:0.7237660576704875\n",
      "RF acc:0.7518111416437672, f1-macro:0.6842288179637237\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def ensemble_predict(row, predictor_cols, default_predictor):\n",
    "\n",
    "    # find majority vote for all methods, :-1 drops ground truth column\n",
    "    votes = Counter(row[predictor_cols]).most_common(1)\n",
    "    \n",
    "    # take svm as tie-breaker because CURRENTLY most accurate\n",
    "    winning_class, highest_num_votes = votes[0]\n",
    "    return winning_class\n",
    "    return row[default_predictor] if highest_num_votes < 2 else winning_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['p_all'] = tfidf_test_df.apply(ensemble_predict, axis = 1, args = (\n",
    "    ['rf_pred','svm_pred','knn_pred'], 'svm_pred',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble acc:0.8142018486135398, f1:0.7312763970924928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sample of test'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_all</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p_all code\n",
       "0     1    1\n",
       "1     0    0\n",
       "2     9    7\n",
       "3     0    0\n",
       "4     4    4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Ensemble acc:{}, f1:{}'.format(accuracy_score(tfidf_test_df['p_all'], y_test), \n",
    "                                      f1_score(tfidf_test_df['p_all'], y_test, average = 'macro')))\n",
    "display(\"sample of test\", tfidf_test_df.iloc[:5][['p_all','code']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
