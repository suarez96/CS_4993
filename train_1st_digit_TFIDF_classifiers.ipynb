{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scripts.TextPreprocessor import TextPreprocessor\n",
    "from scripts.OccupationPreprocessor import OccupationPreprocessor\n",
    "from scripts.TrainEngine import TrainEngine\n",
    "from scripts.Embedder import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/noc_data_get_byws_dealing_slash.csv')\n",
    "df = df.apply(OccupationPreprocessor.extract_job_samples, axis = 1)\n",
    "train_df = pd.DataFrame(dict(OccupationPreprocessor.all_job_samples).items(), columns=['input', 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load ATP data\n",
    "ATP_data = OccupationPreprocessor.prepare_df('./Data/V5_Run Input(1).xlsx', \n",
    "                                             input_column='Current Job Title',\n",
    "                                            code_column='NOC code ',\n",
    "                                             n_digits=4\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle ATP and split into train-val sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_ATP_df = ATP_data.sample(frac=1, random_state=42)\n",
    "\n",
    "# Sample size of ATP used for training \n",
    "ATP_train_size = 8000\n",
    "\n",
    "# Split  dataset \n",
    "ATP_data_train_set = shuffled_ATP_df[:ATP_train_size]\n",
    "ATP_data_test_set = shuffled_ATP_df[ATP_train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.append(ATP_data_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncleaned_train_df = train_df.copy() # for tfidf, note: that tfidf lowercases regardless\n",
    "cleaned_train_df = train_df.copy() # for doc2vec\n",
    "cleaned_train_df['input'] = cleaned_train_df['input'].apply(TextPreprocessor.preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_NAME = 'trial_11'\n",
    "\n",
    "doc2vec_params = dict(\n",
    "epochs = 6144, # training cycles\n",
    "vec_size = 64, # specific to doc2vec, size of the output vector\n",
    "alpha = 0.001, # learning rate\n",
    "window = 3,\n",
    "min_count = 2,\n",
    "min_alpha = 0.00025\n",
    ")\n",
    "\n",
    "embedder = Embedder(\n",
    "    d2v_trial_name=TRIAL_NAME,\n",
    "    d2v_params=doc2vec_params,\n",
    "    train_data = uncleaned_train_df,\n",
    "    corpus_column = 'input',\n",
    "    infer_params = {\n",
    "        'steps':2048,\n",
    "        'alpha':0.03\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.train_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply embeddings to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CODE_LENGTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_vectors = Embedder.get_tfidf_embeddings(embedder, uncleaned_train_df['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_train_vectors\n",
    "y_train = np.array(train_df['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = pd.Series(y_train[:-8000]).value_counts().index,\n",
    "        y=pd.Series(y_train[:-8000]).value_counts()\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "title = 'NOC data: frequency bar plot of each leading digit',\n",
    "    yaxis_title = 'Count',\n",
    "    xaxis_title = 'First Digit'\n",
    ")\n",
    "fig.update_xaxes(tickvals=list(sorted(pd.Series(y_train).unique())))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = pd.Series(y_train[-8000:]).value_counts().index,\n",
    "        y=pd.Series(y_train[-8000:]).value_counts()\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "title = 'ATP data: frequency bar plot of each leading digit',\n",
    "    yaxis_title = 'Count',\n",
    "    xaxis_title = 'First Digit'\n",
    ")\n",
    "fig.update_xaxes(tickvals=list(sorted(pd.Series(y_train).unique())))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = pd.Series(y_train).value_counts().index,\n",
    "        y=pd.Series(y_train).value_counts()\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "title = 'All Train Data: frequency bar plot of each leading digit',\n",
    "    yaxis_title = 'Count',\n",
    "    xaxis_title = 'First Digit'\n",
    ")\n",
    "fig.update_xaxes(tickvals=list(sorted(pd.Series(y_train).unique())))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_vectors = Embedder.get_tfidf_embeddings(embedder, ATP_data_test_set['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first n digits of y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf_test_vectors\n",
    "y_test = np.array(ATP_data_test_set['code'].apply(\n",
    "    OccupationPreprocessor.first_n_digits, args=(TARGET_CODE_LENGTH,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build preliminary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM = SVC(class_weight='balanced', kernel='linear')\n",
    "\n",
    "start = time.time()\n",
    "SVM.fit(X_train, y_train)\n",
    "print('SVM training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=256, max_depth=128, n_jobs=-1, warm_start=True)\n",
    "\n",
    "start = time.time()\n",
    "RF.fit(X_train, y_train)\n",
    "print('RF training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 4, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "KNN.fit(X_train, y_train)\n",
    "print('KNN training duration: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('classifiers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_cw66gEMiQU"
   },
   "source": [
    "# Predict TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWmPefoPEO_c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svm_pred = SVM.predict(X_test)\n",
    "print('SVM prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggSfm8uHERlp"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf_pred = RF.predict(X_test)\n",
    "print('RF prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLvftUL7BD1c"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "knn_pred = KNN.predict(X_test)\n",
    "print('KNN prediction duration on {} samples: {} seconds'.format(X_test.shape[0], time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKhah7vkBD1h"
   },
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvm3AYkfBD1i",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "tfidf_test_df = pd.DataFrame({\n",
    "    'svm_pred':svm_pred,\n",
    "    'rf_pred':rf_pred,\n",
    "    'knn_pred':knn_pred,\n",
    "    'code':y_test\n",
    "})\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for classifier in ['knn','svm', 'rf']:\n",
    "    print('{} acc:{}, f1-macro:{}'.format(classifier.upper(), \n",
    "                                    accuracy_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)], \n",
    "                                        y_test\n",
    "                                    ),\n",
    "                                    f1_score(\n",
    "                                        tfidf_test_df['{}_pred'.format(classifier)],\n",
    "                                        y_test, average = 'macro')\n",
    "                                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def ensemble_predict(row, predictor_cols, default_predictor):\n",
    "\n",
    "    # find majority vote for all methods, :-1 drops ground truth column\n",
    "    votes = Counter(row[predictor_cols]).most_common(1)\n",
    "    \n",
    "    # take svm as tie-breaker because CURRENTLY most accurate\n",
    "    winning_class, highest_num_votes = votes[0]\n",
    "    return winning_class\n",
    "    return row[default_predictor] if highest_num_votes < 2 else winning_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df['p_all'] = tfidf_test_df.apply(ensemble_predict, axis = 1, args = (\n",
    "    ['rf_pred','svm_pred','knn_pred'], 'svm_pred',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df.iloc[:, :10][['p_all','code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ensemble metrics total. Accuracy:{}, f1:{}\\n'.format(accuracy_score(tfidf_test_df['p_all'], y_test), \n",
    "                                      f1_score(tfidf_test_df['p_all'], y_test, average = 'macro')))\n",
    "for target in list(sorted(pd.Series(y_test).unique())):\n",
    "    print(\"---- Target =\", target)\n",
    "    print('Accuracy:{:.2f}'.format(\n",
    "            accuracy_score(\n",
    "                tfidf_test_df['p_all'].loc[y_test == target], \n",
    "                pd.Series(y_test).loc[y_test == target]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the train data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
